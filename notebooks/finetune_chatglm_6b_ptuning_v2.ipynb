{"cells":[{"cell_type":"markdown","metadata":{"id":"X9ECHAz1ckIz"},"source":["# 安装依赖"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42999,"status":"ok","timestamp":1684669669505,"user":{"displayName":"毕弘喆","userId":"15972295281758093677"},"user_tz":-480},"id":"e8UvTt4PUUf2","outputId":"b178268f-5cf9-49a8-eecb-52b11257de0a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'DocQA'...\n","remote: Enumerating objects: 249, done.\u001b[K\n","remote: Counting objects: 100% (69/69), done.\u001b[K\n","remote: Compressing objects: 100% (48/48), done.\u001b[K\n","remote: Total 249 (delta 32), reused 49 (delta 18), pack-reused 180\u001b[K\n","Receiving objects: 100% (249/249), 718.31 MiB | 17.66 MiB/s, done.\n","Resolving deltas: 100% (45/45), done.\n"]}],"source":["!git clone https://github.com/HongzheBi/DocQA.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33022,"status":"ok","timestamp":1684669702525,"user":{"displayName":"毕弘喆","userId":"15972295281758093677"},"user_tz":-480},"id":"CrDaUny4llR3","outputId":"e63e624e-c8b4-4326-b342-507a71ca62d2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch>=1.13.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.0.1+cu118)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (3.20.3)\n","Collecting cpm_kernels (from -r requirements.txt (line 3))\n","  Downloading cpm_kernels-1.0.11-py3-none-any.whl (416 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m416.6/416.6 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sentencepiece (from -r requirements.txt (line 4))\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting transformers>=4.27.4 (from -r requirements.txt (line 5))\n","  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m119.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting datasets>=2.10.0 (from -r requirements.txt (line 6))\n","  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting accelerate>=0.18.0 (from -r requirements.txt (line 7))\n","  Downloading accelerate-0.19.0-py3-none-any.whl (219 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.1/219.1 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting peft>=0.3.0 (from -r requirements.txt (line 8))\n","  Downloading peft-0.3.0-py3-none-any.whl (56 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting trl>=0.4.1 (from -r requirements.txt (line 9))\n","  Downloading trl-0.4.1-py3-none-any.whl (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (0.42.1)\n","Collecting rouge_chinese (from -r requirements.txt (line 11))\n","  Downloading rouge_chinese-1.0.3-py3-none-any.whl (21 kB)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (3.8.1)\n","Collecting gradio (from -r requirements.txt (line 13))\n","  Downloading gradio-3.32.0-py3-none-any.whl (19.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.9/19.9 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting mdtex2html (from -r requirements.txt (line 14))\n","  Downloading mdtex2html-1.2.0-py3-none-any.whl (13 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->-r requirements.txt (line 1)) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->-r requirements.txt (line 1)) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->-r requirements.txt (line 1)) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->-r requirements.txt (line 1)) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->-r requirements.txt (line 1)) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->-r requirements.txt (line 1)) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.1->-r requirements.txt (line 1)) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.1->-r requirements.txt (line 1)) (16.0.5)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers>=4.27.4->-r requirements.txt (line 5))\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.27.4->-r requirements.txt (line 5)) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.27.4->-r requirements.txt (line 5)) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.27.4->-r requirements.txt (line 5)) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.27.4->-r requirements.txt (line 5)) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.27.4->-r requirements.txt (line 5)) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers>=4.27.4->-r requirements.txt (line 5))\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m125.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.27.4->-r requirements.txt (line 5)) (4.65.0)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.10.0->-r requirements.txt (line 6)) (9.0.0)\n","Collecting dill<0.3.7,>=0.3.0 (from datasets>=2.10.0->-r requirements.txt (line 6))\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.10.0->-r requirements.txt (line 6)) (1.5.3)\n","Collecting xxhash (from datasets>=2.10.0->-r requirements.txt (line 6))\n","  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets>=2.10.0->-r requirements.txt (line 6))\n","  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.10.0->-r requirements.txt (line 6)) (2023.4.0)\n","Collecting aiohttp (from datasets>=2.10.0->-r requirements.txt (line 6))\n","  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting responses<0.19 (from datasets>=2.10.0->-r requirements.txt (line 6))\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.18.0->-r requirements.txt (line 7)) (5.9.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge_chinese->-r requirements.txt (line 11)) (1.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->-r requirements.txt (line 12)) (8.1.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->-r requirements.txt (line 12)) (1.2.0)\n","Collecting aiofiles (from gradio->-r requirements.txt (line 13))\n","  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n","Requirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 13)) (4.2.2)\n","Collecting fastapi (from gradio->-r requirements.txt (line 13))\n","  Downloading fastapi-0.95.2-py3-none-any.whl (56 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ffmpy (from gradio->-r requirements.txt (line 13))\n","  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting gradio-client>=0.2.4 (from gradio->-r requirements.txt (line 13))\n","  Downloading gradio_client-0.2.5-py3-none-any.whl (288 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.1/288.1 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpx (from gradio->-r requirements.txt (line 13))\n","  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 13)) (2.2.0)\n","Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 13)) (2.1.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 13)) (3.7.1)\n","Collecting mdit-py-plugins<=0.3.3 (from gradio->-r requirements.txt (line 13))\n","  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting orjson (from gradio->-r requirements.txt (line 13))\n","  Downloading orjson-3.8.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.2/137.2 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 13)) (8.4.0)\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 13)) (1.10.7)\n","Collecting pydub (from gradio->-r requirements.txt (line 13))\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Requirement already satisfied: pygments>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 13)) (2.14.0)\n","Collecting python-multipart (from gradio->-r requirements.txt (line 13))\n","  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting semantic-version (from gradio->-r requirements.txt (line 13))\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Collecting uvicorn>=0.14.0 (from gradio->-r requirements.txt (line 13))\n","  Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting websockets>=10.0 (from gradio->-r requirements.txt (line 13))\n","  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from mdtex2html->-r requirements.txt (line 14)) (3.4.3)\n","Collecting latex2mathml (from mdtex2html->-r requirements.txt (line 14))\n","  Downloading latex2mathml-3.76.0-py3-none-any.whl (73 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio->-r requirements.txt (line 13)) (0.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio->-r requirements.txt (line 13)) (4.3.3)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio->-r requirements.txt (line 13)) (0.12.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.10.0->-r requirements.txt (line 6)) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.10.0->-r requirements.txt (line 6)) (2.0.12)\n","Collecting multidict<7.0,>=4.5 (from aiohttp->datasets>=2.10.0->-r requirements.txt (line 6))\n","  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets>=2.10.0->-r requirements.txt (line 6))\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting yarl<2.0,>=1.0 (from aiohttp->datasets>=2.10.0->-r requirements.txt (line 6))\n","  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets>=2.10.0->-r requirements.txt (line 6))\n","  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->datasets>=2.10.0->-r requirements.txt (line 6))\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio->-r requirements.txt (line 13)) (0.1.2)\n","Collecting linkify-it-py<3,>=1 (from markdown-it-py[linkify]>=2.0.0->gradio->-r requirements.txt (line 13))\n","  Downloading linkify_it_py-2.0.2-py3-none-any.whl (19 kB)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.10.0->-r requirements.txt (line 6)) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.10.0->-r requirements.txt (line 6)) (2022.7.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.27.4->-r requirements.txt (line 5)) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.27.4->-r requirements.txt (line 5)) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.27.4->-r requirements.txt (line 5)) (3.4)\n","Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio->-r requirements.txt (line 13))\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio->-r requirements.txt (line 13))\n","  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpcore<0.18.0,>=0.15.0 (from httpx->gradio->-r requirements.txt (line 13))\n","  Downloading httpcore-0.17.1-py3-none-any.whl (70 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.9/70.9 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio->-r requirements.txt (line 13)) (1.3.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio->-r requirements.txt (line 13)) (1.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio->-r requirements.txt (line 13)) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio->-r requirements.txt (line 13)) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio->-r requirements.txt (line 13)) (1.4.4)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio->-r requirements.txt (line 13)) (3.0.9)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.1->-r requirements.txt (line 1)) (1.3.0)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio->-r requirements.txt (line 13)) (3.6.2)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio->-r requirements.txt (line 13)) (0.19.3)\n","Collecting uc-micro-py (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio->-r requirements.txt (line 13))\n","  Downloading uc_micro_py-1.0.2-py3-none-any.whl (6.2 kB)\n","Building wheels for collected packages: ffmpy\n","  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4694 sha256=ef88bec966e0b56cebebf6f34e25acfc146d494b61bc000d68ad6e6949a3d9d0\n","  Stored in directory: /root/.cache/pip/wheels/0c/c2/0e/3b9c6845c6a4e35beb90910cc70d9ac9ab5d47402bd62af0df\n","Successfully built ffmpy\n","Installing collected packages: tokenizers, sentencepiece, pydub, ffmpy, cpm_kernels, xxhash, websockets, uc-micro-py, semantic-version, rouge_chinese, python-multipart, orjson, multidict, latex2mathml, h11, frozenlist, dill, async-timeout, aiofiles, yarl, uvicorn, starlette, responses, multiprocess, mdtex2html, mdit-py-plugins, linkify-it-py, huggingface-hub, httpcore, aiosignal, transformers, httpx, fastapi, aiohttp, gradio-client, gradio, datasets, accelerate, trl, peft\n","Successfully installed accelerate-0.19.0 aiofiles-23.1.0 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 cpm_kernels-1.0.11 datasets-2.12.0 dill-0.3.6 fastapi-0.95.2 ffmpy-0.3.0 frozenlist-1.3.3 gradio-3.32.0 gradio-client-0.2.5 h11-0.14.0 httpcore-0.17.1 httpx-0.24.1 huggingface-hub-0.14.1 latex2mathml-3.76.0 linkify-it-py-2.0.2 mdit-py-plugins-0.3.3 mdtex2html-1.2.0 multidict-6.0.4 multiprocess-0.70.14 orjson-3.8.12 peft-0.3.0 pydub-0.25.1 python-multipart-0.0.6 responses-0.18.0 rouge_chinese-1.0.3 semantic-version-2.10.0 sentencepiece-0.1.99 starlette-0.27.0 tokenizers-0.13.3 transformers-4.29.2 trl-0.4.1 uc-micro-py-1.0.2 uvicorn-0.22.0 websockets-11.0.3 xxhash-3.2.0 yarl-1.9.2\n"]}],"source":["!cd DocQA/finetune/ && pip install -r requirements.txt"]},{"cell_type":"markdown","metadata":{"id":"yrphP_4OevFZ"},"source":["# LoRA微调"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kr-XUKJkwbnM"},"outputs":[],"source":["!mkdir sft_checkpoint\n","!mkdir output"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OLyZbcw3lxQq","outputId":"6941a08a-6fb9-4e12-8acb-4c8c61471a95","executionInfo":{"status":"ok","timestamp":1684679835506,"user_tz":-480,"elapsed":2331738,"user":{"displayName":"毕弘喆","userId":"15972295281758093677"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-05-21 11:48:29.450838: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","05/21/2023 11:48:32 - WARNING - utils.common - Process rank: 0, device: cuda:0, n_gpu: 1\n","  distributed training: True, 16-bits training: True\n","05/21/2023 11:48:32 - INFO - utils.common - Training/evaluation parameters Seq2SeqTrainingArguments(\n","_n_gpu=1,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_backend=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","do_eval=False,\n","do_predict=False,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_steps=None,\n","evaluation_strategy=no,\n","fp16=True,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","generation_config=None,\n","generation_max_length=None,\n","generation_num_beams=None,\n","gradient_accumulation_steps=4,\n","gradient_checkpointing=False,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_model_id=None,\n","hub_private_repo=False,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_inputs_for_metrics=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=0.02,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=/content/sft_checkpoint/runs/May21_11-48-32_5e7a278942ad,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=10,\n","logging_strategy=steps,\n","lr_scheduler_type=cosine,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=adamw_torch,\n","optim_args=None,\n","output_dir=/content/sft_checkpoint,\n","overwrite_output_dir=False,\n","past_index=-1,\n","per_device_eval_batch_size=8,\n","per_device_train_batch_size=8,\n","predict_with_generate=False,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard'],\n","resume_from_checkpoint=None,\n","run_name=/content/sft_checkpoint,\n","save_on_each_node=False,\n","save_safetensors=False,\n","save_steps=1000,\n","save_strategy=steps,\n","save_total_limit=None,\n","seed=42,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","sortish_sampler=False,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torchdynamo=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n","xpu_backend=None,\n",")\n","05/21/2023 11:48:32 - INFO - utils.common - Loading dataset DatasetAttr(load_from='hf_hub', dataset_name='suolyer/webqa', file_name=None, file_sha1=None)...\n","05/21/2023 11:48:34 - INFO - datasets.utils.file_utils - https://huggingface.co/datasets/suolyer/webqa/resolve/main/README.md not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmpehy_rtqn\n","Downloading readme: 100% 28.0/28.0 [00:00<00:00, 26.7kB/s]\n","05/21/2023 11:48:34 - INFO - datasets.utils.file_utils - storing https://huggingface.co/datasets/suolyer/webqa/resolve/main/README.md in cache at /root/.cache/huggingface/datasets/downloads/e0150768bc47edb9ae095795b129541a3219da8a914a9c1db3f04628461f5989.dfd6587e58d78649c8fd0eacb7047496cbd5c5126aacc96ccce8485b144b2e82\n","05/21/2023 11:48:34 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/e0150768bc47edb9ae095795b129541a3219da8a914a9c1db3f04628461f5989.dfd6587e58d78649c8fd0eacb7047496cbd5c5126aacc96ccce8485b144b2e82\n","05/21/2023 11:48:34 - INFO - datasets.builder - Using custom data configuration suolyer--webqa-7107602b65a20e87\n","05/21/2023 11:48:34 - INFO - datasets.info - Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","05/21/2023 11:48:34 - INFO - datasets.builder - Generating dataset json (/root/.cache/huggingface/datasets/suolyer___json/suolyer--webqa-7107602b65a20e87/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n","Downloading and preparing dataset json/suolyer--webqa to /root/.cache/huggingface/datasets/suolyer___json/suolyer--webqa-7107602b65a20e87/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n","05/21/2023 11:48:36 - INFO - datasets.builder - Dataset not on Hf google storage. Downloading and preparing it from source\n","Downloading data files:   0% 0/3 [00:00<?, ?it/s]05/21/2023 11:48:36 - INFO - datasets.utils.file_utils - https://huggingface.co/datasets/suolyer/webqa/resolve/5bb7ba2f15fe38700284f91c7a995690a15419b6/train.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmpzc46h5wt\n","\n","Downloading data:   0% 0.00/14.8M [00:00<?, ?B/s]\u001b[A\n","Downloading data: 100% 14.8M/14.8M [00:00<00:00, 111MB/s]\n","05/21/2023 11:48:36 - INFO - datasets.utils.file_utils - storing https://huggingface.co/datasets/suolyer/webqa/resolve/5bb7ba2f15fe38700284f91c7a995690a15419b6/train.json in cache at /root/.cache/huggingface/datasets/downloads/b6d6a1295603250c087db688cdce8041a290807c9018a883c5a1769317a9f16a\n","05/21/2023 11:48:36 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/b6d6a1295603250c087db688cdce8041a290807c9018a883c5a1769317a9f16a\n","Downloading data files:  33% 1/3 [00:00<00:01,  1.49it/s]05/21/2023 11:48:36 - INFO - datasets.utils.file_utils - https://huggingface.co/datasets/suolyer/webqa/resolve/5bb7ba2f15fe38700284f91c7a995690a15419b6/dev.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmp098k3ipj\n","\n","Downloading data: 100% 864k/864k [00:00<00:00, 73.2MB/s]\n","05/21/2023 11:48:37 - INFO - datasets.utils.file_utils - storing https://huggingface.co/datasets/suolyer/webqa/resolve/5bb7ba2f15fe38700284f91c7a995690a15419b6/dev.json in cache at /root/.cache/huggingface/datasets/downloads/851bd9d9c0691ebe234d620bf7d8d699228e4a30e92b70deb433096f1e2d11c3\n","05/21/2023 11:48:37 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/851bd9d9c0691ebe234d620bf7d8d699228e4a30e92b70deb433096f1e2d11c3\n","Downloading data files:  67% 2/3 [00:01<00:00,  1.67it/s]05/21/2023 11:48:37 - INFO - datasets.utils.file_utils - https://huggingface.co/datasets/suolyer/webqa/resolve/5bb7ba2f15fe38700284f91c7a995690a15419b6/test.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmpkyppie9_\n","\n","Downloading data:   0% 0.00/869k [00:00<?, ?B/s]\u001b[A\n","Downloading data:  31% 272k/869k [00:00<00:00, 1.30MB/s]\u001b[A\n","Downloading data: 100% 869k/869k [00:00<00:00, 2.05MB/s]\n","05/21/2023 11:48:38 - INFO - datasets.utils.file_utils - storing https://huggingface.co/datasets/suolyer/webqa/resolve/5bb7ba2f15fe38700284f91c7a995690a15419b6/test.json in cache at /root/.cache/huggingface/datasets/downloads/74543b508cfec5eacc2e5c49c8a0e69c14413ae327cef1b144ebbdf38734047c\n","05/21/2023 11:48:38 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/74543b508cfec5eacc2e5c49c8a0e69c14413ae327cef1b144ebbdf38734047c\n","Downloading data files: 100% 3/3 [00:02<00:00,  1.39it/s]\n","05/21/2023 11:48:38 - INFO - datasets.download.download_manager - Downloading took 0.0 min\n","05/21/2023 11:48:38 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min\n","Extracting data files: 100% 3/3 [00:00<00:00, 1976.27it/s]\n","05/21/2023 11:48:38 - INFO - datasets.builder - Generating train split\n","05/21/2023 11:48:38 - INFO - datasets.builder - Generating validation split\n","05/21/2023 11:48:38 - INFO - datasets.builder - Generating test split\n","05/21/2023 11:48:38 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n","Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/suolyer___json/suolyer--webqa-7107602b65a20e87/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n","100% 3/3 [00:00<00:00, 451.02it/s]\n","Downloading (…)okenizer_config.json: 100% 441/441 [00:00<00:00, 3.04MB/s]\n","Downloading (…)enization_chatglm.py: 100% 16.7k/16.7k [00:00<00:00, 60.6MB/s]\n","[WARNING|dynamic_module_utils.py:323] 2023-05-21 11:48:39,294 >> A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm-6b:\n","- tokenization_chatglm.py\n",". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","Downloading ice_text.model: 100% 2.71M/2.71M [00:00<00:00, 171MB/s]\n","[INFO|tokenization_utils_base.py:1810] 2023-05-21 11:48:40,003 >> loading file ice_text.model from cache at /root/.cache/huggingface/hub/models--THUDM--chatglm-6b/snapshots/a8ede826cf1b62bd3c78bdfb3625c7c5d2048fbd/ice_text.model\n","[INFO|tokenization_utils_base.py:1810] 2023-05-21 11:48:40,003 >> loading file added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:1810] 2023-05-21 11:48:40,003 >> loading file special_tokens_map.json from cache at None\n","[INFO|tokenization_utils_base.py:1810] 2023-05-21 11:48:40,003 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--THUDM--chatglm-6b/snapshots/a8ede826cf1b62bd3c78bdfb3625c7c5d2048fbd/tokenizer_config.json\n","Downloading (…)d2048fbd/config.json: 100% 773/773 [00:00<00:00, 5.46MB/s]\n","[INFO|configuration_utils.py:669] 2023-05-21 11:48:40,693 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--THUDM--chatglm-6b/snapshots/a8ede826cf1b62bd3c78bdfb3625c7c5d2048fbd/config.json\n","Downloading (…)iguration_chatglm.py: 100% 4.28k/4.28k [00:00<00:00, 23.4MB/s]\n","[WARNING|dynamic_module_utils.py:323] 2023-05-21 11:48:41,141 >> A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm-6b:\n","- configuration_chatglm.py\n",". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","[INFO|configuration_utils.py:669] 2023-05-21 11:48:41,143 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--THUDM--chatglm-6b/snapshots/a8ede826cf1b62bd3c78bdfb3625c7c5d2048fbd/config.json\n","[INFO|configuration_utils.py:725] 2023-05-21 11:48:41,144 >> Model config ChatGLMConfig {\n","  \"_name_or_path\": \"THUDM/chatglm-6b\",\n","  \"architectures\": [\n","    \"ChatGLMModel\"\n","  ],\n","  \"auto_map\": {\n","    \"AutoConfig\": \"THUDM/chatglm-6b--configuration_chatglm.ChatGLMConfig\",\n","    \"AutoModel\": \"THUDM/chatglm-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n","    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm-6b--modeling_chatglm.ChatGLMForConditionalGeneration\"\n","  },\n","  \"bos_token_id\": 130004,\n","  \"eos_token_id\": 130005,\n","  \"gmask_token_id\": 130001,\n","  \"hidden_size\": 4096,\n","  \"inner_hidden_size\": 16384,\n","  \"layernorm_epsilon\": 1e-05,\n","  \"mask_token_id\": 130000,\n","  \"max_sequence_length\": 2048,\n","  \"model_type\": \"chatglm\",\n","  \"num_attention_heads\": 32,\n","  \"num_layers\": 28,\n","  \"pad_token_id\": 3,\n","  \"position_encoding_2d\": true,\n","  \"pre_seq_len\": null,\n","  \"prefix_projection\": false,\n","  \"quantization_bit\": 0,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.29.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 130528\n","}\n","\n","Downloading (…)/modeling_chatglm.py: 100% 57.6k/57.6k [00:00<00:00, 273kB/s]\n","Downloading (…)main/quantization.py: 100% 15.1k/15.1k [00:00<00:00, 62.8MB/s]\n","[WARNING|dynamic_module_utils.py:323] 2023-05-21 11:48:42,516 >> A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm-6b:\n","- quantization.py\n",". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","[WARNING|dynamic_module_utils.py:323] 2023-05-21 11:48:42,516 >> A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm-6b:\n","- modeling_chatglm.py\n","- quantization.py\n",". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","Downloading (…)model.bin.index.json: 100% 33.4k/33.4k [00:00<00:00, 113MB/s]\n","[INFO|modeling_utils.py:2516] 2023-05-21 11:48:43,233 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--THUDM--chatglm-6b/snapshots/a8ede826cf1b62bd3c78bdfb3625c7c5d2048fbd/pytorch_model.bin.index.json\n","Downloading shards:   0% 0/8 [00:00<?, ?it/s]\n","Downloading (…)l-00001-of-00008.bin:   0% 0.00/1.74G [00:00<?, ?B/s]\u001b[A\n","Downloading (…)l-00001-of-00008.bin:   2% 41.9M/1.74G [00:00<00:04, 347MB/s]\u001b[A\n","Downloading (…)l-00001-of-00008.bin:   5% 94.4M/1.74G [00:00<00:04, 396MB/s]\u001b[A\n","Downloading (…)l-00001-of-00008.bin:   8% 147M/1.74G [00:00<00:03, 420MB/s] \u001b[A\n","Downloading (…)l-00001-of-00008.bin:  11% 199M/1.74G [00:00<00:03, 441MB/s]\u001b[A\n","Downloading (…)l-00001-of-00008.bin:  15% 262M/1.74G [00:00<00:03, 487MB/s]\u001b[A\n","Downloading (…)l-00001-of-00008.bin:  19% 325M/1.74G [00:00<00:02, 498MB/s]\u001b[A\n","Downloading (…)l-00001-of-00008.bin:  22% 377M/1.74G [00:00<00:03, 440MB/s]\u001b[A\n","Downloading (…)l-00001-of-00008.bin:  25% 430M/1.74G [00:00<00:02, 451MB/s]\u001b[A\n","Downloading (…)l-00001-of-00008.bin:  28% 482M/1.74G [00:01<00:02, 440MB/s]\u001b[A\n","Downloading (…)l-00001-of-00008.bin:  31% 535M/1.74G [00:01<00:02, 421MB/s]\u001b[A\n","Downloading (…)l-00001-of-00008.bin:  34% 587M/1.74G [00:01<00:02, 442MB/s]\u001b[A\n","Downloading (…)l-00001-of-00008.bin:  37% 650M/1.74G [00:01<00:02, 476MB/s]\u001b[A\n","Downloading (…)l-00001-of-00008.bin:  41% 713M/1.74G [00:01<00:02, 505MB/s]\u001b[A\n","Downloading (…)l-00001-of-00008.bin:  45% 776M/1.74G [00:01<00:01, 524MB/s]\u001b[A\n","Downloading (…)l-00001-of-00008.bin:  48% 839M/1.74G [00:01<00:01, 539MB/s]\u001b[A\n","Downloading (…)l-00001-of-00008.bin:  52% 902M/1.74G [00:01<00:01, 532MB/s]\u001b[A\n","Downloading (…)l-00001-of-00008.bin:  55% 965M/1.74G [00:02<00:01, 479MB/s]\u001b[A\n","Downloading (…)l-00001-of-00008.bin:  58% 1.02G/1.74G [00:02<00:01, 444MB/s]\u001b[A\n","Downloading (…)l-00001-of-00008.bin:  61% 1.07G/1.74G [00:02<00:01, 425MB/s]\u001b[A\n","Downloading (…)l-00001-of-00008.bin:  64% 1.12G/1.74G [00:02<00:01, 416MB/s]\u001b[A\n","Downloading (…)l-00001-of-00008.bin:  67% 1.17G/1.74G [00:02<00:01, 429MB/s]\u001b[A\n","Downloading (…)l-00001-of-00008.bin:  70% 1.23G/1.74G [00:02<00:01, 440MB/s]\u001b[A\n","Downloading (…)l-00001-of-00008.bin:  73% 1.28G/1.74G [00:02<00:01, 453MB/s]\u001b[A\n","Downloading (…)l-00001-of-00008.bin:  77% 1.33G/1.74G [00:02<00:00, 440MB/s]\u001b[A\n","Downloading (…)l-00001-of-00008.bin:  80% 1.38G/1.74G [00:03<00:00, 438MB/s]\u001b[A\n","Downloading (…)l-00001-of-00008.bin:  83% 1.44G/1.74G [00:03<00:00, 448MB/s]\u001b[A\n","Downloading (…)l-00001-of-00008.bin:  86% 1.49G/1.74G [00:03<00:00, 463MB/s]\u001b[A\n","Downloading (…)l-00001-of-00008.bin:  89% 1.54G/1.74G [00:03<00:00, 472MB/s]\u001b[A\n","Downloading (…)l-00001-of-00008.bin:  92% 1.59G/1.74G [00:03<00:00, 481MB/s]\u001b[A\n","Downloading (…)l-00001-of-00008.bin:  95% 1.65G/1.74G [00:03<00:00, 488MB/s]\u001b[A\n","Downloading (…)l-00001-of-00008.bin: 100% 1.74G/1.74G [00:03<00:00, 461MB/s]\n","Downloading shards:  12% 1/8 [00:04<00:28,  4.01s/it]\n","Downloading (…)l-00002-of-00008.bin:   0% 0.00/1.88G [00:00<?, ?B/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:   3% 52.4M/1.88G [00:00<00:03, 459MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:   6% 105M/1.88G [00:00<00:03, 479MB/s] \u001b[A\n","Downloading (…)l-00002-of-00008.bin:   8% 157M/1.88G [00:00<00:03, 493MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:  11% 210M/1.88G [00:00<00:03, 453MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:  14% 262M/1.88G [00:00<00:03, 448MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:  17% 325M/1.88G [00:00<00:03, 480MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:  20% 377M/1.88G [00:00<00:03, 493MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:  23% 430M/1.88G [00:00<00:02, 486MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:  26% 482M/1.88G [00:01<00:02, 475MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:  28% 535M/1.88G [00:01<00:02, 464MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:  31% 587M/1.88G [00:01<00:03, 425MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:  34% 640M/1.88G [00:01<00:02, 442MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:  37% 692M/1.88G [00:01<00:02, 454MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:  40% 744M/1.88G [00:01<00:02, 469MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:  42% 797M/1.88G [00:01<00:02, 437MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:  45% 849M/1.88G [00:01<00:02, 441MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:  48% 902M/1.88G [00:01<00:02, 436MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:  51% 954M/1.88G [00:02<00:02, 397MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:  53% 996M/1.88G [00:02<00:02, 329MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:  55% 1.04G/1.88G [00:02<00:02, 299MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:  57% 1.08G/1.88G [00:02<00:02, 271MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:  59% 1.11G/1.88G [00:02<00:02, 256MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:  61% 1.14G/1.88G [00:02<00:03, 242MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:  62% 1.17G/1.88G [00:03<00:03, 230MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:  64% 1.21G/1.88G [00:03<00:03, 219MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:  66% 1.24G/1.88G [00:03<00:03, 212MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:  67% 1.27G/1.88G [00:03<00:02, 209MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:  69% 1.30G/1.88G [00:03<00:02, 208MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:  71% 1.33G/1.88G [00:03<00:02, 209MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:  73% 1.36G/1.88G [00:04<00:02, 209MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:  74% 1.39G/1.88G [00:04<00:02, 214MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:  76% 1.43G/1.88G [00:04<00:02, 218MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:  78% 1.46G/1.88G [00:04<00:01, 222MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:  80% 1.50G/1.88G [00:04<00:01, 255MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:  81% 1.53G/1.88G [00:04<00:01, 268MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:  84% 1.57G/1.88G [00:04<00:01, 275MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:  86% 1.63G/1.88G [00:04<00:00, 318MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:  89% 1.67G/1.88G [00:05<00:00, 311MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:  91% 1.71G/1.88G [00:05<00:00, 325MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:  93% 1.75G/1.88G [00:05<00:00, 308MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:  95% 1.79G/1.88G [00:05<00:00, 325MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin:  98% 1.84G/1.88G [00:05<00:00, 334MB/s]\u001b[A\n","Downloading (…)l-00002-of-00008.bin: 100% 1.88G/1.88G [00:05<00:00, 327MB/s]\n","Downloading shards:  25% 2/8 [00:10<00:31,  5.17s/it]\n","Downloading (…)l-00003-of-00008.bin:   0% 0.00/1.98G [00:00<?, ?B/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:   3% 52.4M/1.98G [00:00<00:04, 444MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:   5% 105M/1.98G [00:00<00:03, 487MB/s] \u001b[A\n","Downloading (…)l-00003-of-00008.bin:   8% 157M/1.98G [00:00<00:03, 502MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:  11% 210M/1.98G [00:00<00:03, 459MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:  13% 262M/1.98G [00:00<00:03, 473MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:  16% 315M/1.98G [00:00<00:03, 476MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:  19% 367M/1.98G [00:00<00:03, 416MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:  21% 419M/1.98G [00:00<00:03, 415MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:  24% 472M/1.98G [00:01<00:03, 408MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:  26% 514M/1.98G [00:01<00:03, 399MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:  28% 556M/1.98G [00:01<00:03, 386MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:  30% 598M/1.98G [00:01<00:05, 250MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:  33% 661M/1.98G [00:01<00:04, 316MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:  37% 724M/1.98G [00:01<00:03, 364MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:  39% 776M/1.98G [00:02<00:03, 361MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:  41% 818M/1.98G [00:02<00:03, 349MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:  43% 860M/1.98G [00:02<00:03, 355MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:  46% 902M/1.98G [00:02<00:03, 349MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:  48% 944M/1.98G [00:02<00:03, 332MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:  50% 986M/1.98G [00:02<00:02, 341MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:  52% 1.03G/1.98G [00:02<00:02, 342MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:  54% 1.07G/1.98G [00:02<00:02, 352MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:  56% 1.11G/1.98G [00:02<00:02, 359MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:  59% 1.16G/1.98G [00:03<00:02, 381MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:  61% 1.21G/1.98G [00:03<00:02, 385MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:  64% 1.26G/1.98G [00:03<00:01, 413MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:  66% 1.31G/1.98G [00:03<00:01, 424MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:  69% 1.36G/1.98G [00:03<00:01, 403MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:  71% 1.41G/1.98G [00:03<00:01, 379MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:  73% 1.45G/1.98G [00:03<00:01, 371MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:  75% 1.49G/1.98G [00:03<00:01, 374MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:  77% 1.53G/1.98G [00:04<00:01, 362MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:  79% 1.57G/1.98G [00:04<00:01, 349MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:  82% 1.61G/1.98G [00:04<00:01, 343MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:  84% 1.66G/1.98G [00:04<00:00, 344MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:  86% 1.70G/1.98G [00:04<00:00, 338MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:  88% 1.74G/1.98G [00:04<00:00, 337MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:  90% 1.78G/1.98G [00:04<00:00, 332MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:  92% 1.82G/1.98G [00:04<00:00, 336MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:  94% 1.87G/1.98G [00:05<00:00, 324MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:  96% 1.91G/1.98G [00:05<00:00, 308MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin:  98% 1.94G/1.98G [00:05<00:00, 305MB/s]\u001b[A\n","Downloading (…)l-00003-of-00008.bin: 100% 1.98G/1.98G [00:05<00:00, 359MB/s]\n","Downloading shards:  38% 3/8 [00:16<00:28,  5.64s/it]\n","Downloading (…)l-00004-of-00008.bin:   0% 0.00/1.91G [00:00<?, ?B/s]\u001b[A\n","Downloading (…)l-00004-of-00008.bin:   2% 41.9M/1.91G [00:00<00:04, 375MB/s]\u001b[A\n","Downloading (…)l-00004-of-00008.bin:   4% 83.9M/1.91G [00:00<00:04, 367MB/s]\u001b[A\n","Downloading (…)l-00004-of-00008.bin:   7% 126M/1.91G [00:00<00:05, 356MB/s] \u001b[A\n","Downloading (…)l-00004-of-00008.bin:   9% 168M/1.91G [00:00<00:04, 362MB/s]\u001b[A\n","Downloading (…)l-00004-of-00008.bin:  12% 220M/1.91G [00:00<00:04, 386MB/s]\u001b[A\n","Downloading (…)l-00004-of-00008.bin:  14% 273M/1.91G [00:00<00:04, 404MB/s]\u001b[A\n","Downloading (…)l-00004-of-00008.bin:  16% 315M/1.91G [00:00<00:04, 397MB/s]\u001b[A\n","Downloading (…)l-00004-of-00008.bin:  19% 367M/1.91G [00:00<00:03, 414MB/s]\u001b[A\n","Downloading (…)l-00004-of-00008.bin:  22% 419M/1.91G [00:01<00:03, 432MB/s]\u001b[A\n","Downloading (…)l-00004-of-00008.bin:  25% 472M/1.91G [00:01<00:03, 408MB/s]\u001b[A\n","Downloading (…)l-00004-of-00008.bin:  27% 524M/1.91G [00:01<00:03, 424MB/s]\u001b[A\n","Downloading (…)l-00004-of-00008.bin:  30% 577M/1.91G [00:01<00:03, 437MB/s]\u001b[A\n","Downloading (…)l-00004-of-00008.bin:  33% 629M/1.91G [00:01<00:02, 444MB/s]\u001b[A\n","Downloading (…)l-00004-of-00008.bin:  36% 682M/1.91G [00:01<00:02, 431MB/s]\u001b[A\n","Downloading (…)l-00004-of-00008.bin:  38% 734M/1.91G [00:01<00:02, 436MB/s]\u001b[A\n","Downloading (…)l-00004-of-00008.bin:  41% 786M/1.91G [00:01<00:02, 432MB/s]\u001b[A\n","Downloading (…)l-00004-of-00008.bin:  44% 839M/1.91G [00:02<00:02, 434MB/s]\u001b[A\n","Downloading (…)l-00004-of-00008.bin:  47% 891M/1.91G [00:02<00:02, 439MB/s]\u001b[A\n","Downloading (…)l-00004-of-00008.bin:  49% 944M/1.91G [00:02<00:02, 413MB/s]\u001b[A\n","Downloading (…)l-00004-of-00008.bin:  52% 986M/1.91G [00:02<00:02, 410MB/s]\u001b[A\n","Downloading (…)l-00004-of-00008.bin:  54% 1.04G/1.91G [00:02<00:02, 422MB/s]\u001b[A\n","Downloading (…)l-00004-of-00008.bin:  58% 1.10G/1.91G [00:02<00:01, 455MB/s]\u001b[A\n","Downloading (…)l-00004-of-00008.bin:  60% 1.15G/1.91G [00:02<00:01, 457MB/s]\u001b[A\n","Downloading (…)l-00004-of-00008.bin:  63% 1.21G/1.91G [00:02<00:01, 458MB/s]\u001b[A\n","Downloading (…)l-00004-of-00008.bin:  66% 1.26G/1.91G [00:02<00:01, 465MB/s]\u001b[A\n","Downloading (…)l-00004-of-00008.bin:  69% 1.31G/1.91G [00:03<00:01, 462MB/s]\u001b[A\n","Downloading (…)l-00004-of-00008.bin:  71% 1.36G/1.91G [00:03<00:01, 455MB/s]\u001b[A\n","Downloading (…)l-00004-of-00008.bin:  74% 1.42G/1.91G [00:03<00:01, 448MB/s]\u001b[A\n","Downloading (…)l-00004-of-00008.bin:  77% 1.47G/1.91G [00:03<00:00, 460MB/s]\u001b[A\n","Downloading (…)l-00004-of-00008.bin:  79% 1.52G/1.91G [00:03<00:00, 452MB/s]\u001b[A\n","Downloading (…)l-00004-of-00008.bin:  82% 1.57G/1.91G [00:03<00:00, 437MB/s]\u001b[A\n","Downloading (…)l-00004-of-00008.bin:  85% 1.63G/1.91G [00:03<00:00, 435MB/s]\u001b[A\n","Downloading (…)l-00004-of-00008.bin:  88% 1.68G/1.91G [00:03<00:00, 422MB/s]\u001b[A\n","Downloading (…)l-00004-of-00008.bin:  90% 1.73G/1.91G [00:04<00:00, 417MB/s]\u001b[A\n","Downloading (…)l-00004-of-00008.bin:  93% 1.78G/1.91G [00:04<00:00, 427MB/s]\u001b[A\n","Downloading (…)l-00004-of-00008.bin:  96% 1.84G/1.91G [00:04<00:00, 425MB/s]\u001b[A\n","Downloading (…)l-00004-of-00008.bin: 100% 1.91G/1.91G [00:04<00:00, 427MB/s]\n","Downloading shards:  50% 4/8 [00:20<00:21,  5.27s/it]\n","Downloading (…)l-00005-of-00008.bin:   0% 0.00/1.88G [00:00<?, ?B/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:   3% 52.4M/1.88G [00:00<00:04, 440MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:   6% 105M/1.88G [00:00<00:04, 412MB/s] \u001b[A\n","Downloading (…)l-00005-of-00008.bin:   8% 147M/1.88G [00:00<00:04, 374MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  11% 199M/1.88G [00:00<00:04, 420MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  14% 262M/1.88G [00:00<00:03, 464MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  17% 315M/1.88G [00:00<00:03, 460MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  20% 367M/1.88G [00:01<00:05, 285MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  22% 419M/1.88G [00:01<00:04, 326MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  26% 482M/1.88G [00:01<00:03, 368MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  28% 535M/1.88G [00:01<00:03, 379MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  31% 587M/1.88G [00:01<00:03, 381MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  34% 640M/1.88G [00:01<00:03, 407MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  37% 692M/1.88G [00:01<00:03, 345MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  39% 734M/1.88G [00:02<00:03, 299MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  41% 776M/1.88G [00:02<00:04, 269MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  43% 807M/1.88G [00:02<00:04, 250MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  45% 839M/1.88G [00:02<00:04, 228MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  46% 870M/1.88G [00:02<00:04, 213MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  48% 902M/1.88G [00:02<00:04, 196MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  49% 923M/1.88G [00:03<00:05, 182MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  50% 944M/1.88G [00:03<00:05, 168MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  51% 965M/1.88G [00:03<00:05, 163MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  52% 986M/1.88G [00:03<00:05, 155MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  54% 1.01G/1.88G [00:03<00:05, 153MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  55% 1.03G/1.88G [00:03<00:05, 160MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  57% 1.07G/1.88G [00:03<00:03, 205MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  59% 1.11G/1.88G [00:04<00:03, 244MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  61% 1.15G/1.88G [00:04<00:02, 284MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  64% 1.20G/1.88G [00:04<00:02, 311MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  66% 1.24G/1.88G [00:04<00:01, 327MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  68% 1.28G/1.88G [00:04<00:01, 321MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  70% 1.32G/1.88G [00:04<00:01, 306MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  73% 1.37G/1.88G [00:04<00:01, 351MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  75% 1.42G/1.88G [00:04<00:01, 338MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  78% 1.46G/1.88G [00:05<00:01, 324MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  80% 1.50G/1.88G [00:05<00:01, 316MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  82% 1.54G/1.88G [00:05<00:01, 305MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  84% 1.57G/1.88G [00:05<00:01, 300MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  85% 1.60G/1.88G [00:05<00:00, 289MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  87% 1.64G/1.88G [00:05<00:00, 276MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  89% 1.67G/1.88G [00:05<00:00, 278MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  90% 1.70G/1.88G [00:05<00:00, 279MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  92% 1.73G/1.88G [00:06<00:00, 270MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  94% 1.76G/1.88G [00:06<00:00, 267MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  95% 1.79G/1.88G [00:06<00:00, 266MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin:  97% 1.82G/1.88G [00:06<00:00, 258MB/s]\u001b[A\n","Downloading (…)l-00005-of-00008.bin: 100% 1.88G/1.88G [00:06<00:00, 283MB/s]\n","Downloading shards:  62% 5/8 [00:27<00:17,  5.86s/it]\n","Downloading (…)l-00006-of-00008.bin:   0% 0.00/1.88G [00:00<?, ?B/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:   2% 31.5M/1.88G [00:00<00:05, 313MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:   4% 83.9M/1.88G [00:00<00:04, 425MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:   7% 136M/1.88G [00:00<00:04, 398MB/s] \u001b[A\n","Downloading (…)l-00006-of-00008.bin:  11% 199M/1.88G [00:00<00:03, 464MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  13% 252M/1.88G [00:00<00:03, 470MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  16% 304M/1.88G [00:00<00:03, 423MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  19% 357M/1.88G [00:00<00:03, 450MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  22% 409M/1.88G [00:02<00:15, 95.9MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  24% 451M/1.88G [00:02<00:12, 116MB/s] \u001b[A\n","Downloading (…)l-00006-of-00008.bin:  26% 482M/1.88G [00:02<00:10, 132MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  28% 524M/1.88G [00:02<00:08, 161MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  31% 577M/1.88G [00:02<00:06, 211MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  33% 619M/1.88G [00:03<00:06, 203MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  36% 671M/1.88G [00:03<00:04, 251MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  38% 713M/1.88G [00:03<00:04, 281MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  40% 755M/1.88G [00:03<00:04, 258MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  42% 797M/1.88G [00:03<00:04, 251MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  44% 828M/1.88G [00:03<00:04, 242MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  46% 860M/1.88G [00:03<00:04, 251MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  47% 891M/1.88G [00:03<00:03, 264MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  49% 923M/1.88G [00:04<00:03, 270MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  51% 954M/1.88G [00:04<00:03, 272MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  52% 986M/1.88G [00:04<00:03, 273MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  54% 1.02G/1.88G [00:04<00:03, 279MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  56% 1.05G/1.88G [00:04<00:02, 283MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  57% 1.08G/1.88G [00:04<00:02, 291MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  59% 1.11G/1.88G [00:04<00:02, 290MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  61% 1.14G/1.88G [00:04<00:02, 289MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  62% 1.17G/1.88G [00:04<00:02, 280MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  64% 1.21G/1.88G [00:05<00:02, 275MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  66% 1.24G/1.88G [00:05<00:03, 193MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  69% 1.29G/1.88G [00:05<00:02, 260MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  71% 1.33G/1.88G [00:05<00:01, 274MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  73% 1.36G/1.88G [00:05<00:02, 253MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  74% 1.39G/1.88G [00:05<00:02, 234MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  76% 1.43G/1.88G [00:06<00:02, 224MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  78% 1.46G/1.88G [00:06<00:02, 203MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  79% 1.49G/1.88G [00:06<00:02, 188MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  80% 1.51G/1.88G [00:06<00:02, 183MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  81% 1.53G/1.88G [00:06<00:02, 173MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  83% 1.55G/1.88G [00:06<00:01, 169MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  85% 1.59G/1.88G [00:06<00:01, 215MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  86% 1.63G/1.88G [00:07<00:01, 238MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  89% 1.67G/1.88G [00:07<00:00, 269MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  90% 1.70G/1.88G [00:07<00:00, 271MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  92% 1.73G/1.88G [00:07<00:00, 258MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  95% 1.78G/1.88G [00:07<00:00, 279MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin:  98% 1.84G/1.88G [00:07<00:00, 310MB/s]\u001b[A\n","Downloading (…)l-00006-of-00008.bin: 100% 1.88G/1.88G [00:07<00:00, 239MB/s]\n","Downloading shards:  75% 6/8 [00:35<00:13,  6.62s/it]\n","Downloading (…)l-00007-of-00008.bin:   0% 0.00/1.07G [00:00<?, ?B/s]\u001b[A\n","Downloading (…)l-00007-of-00008.bin:   4% 41.9M/1.07G [00:00<00:02, 413MB/s]\u001b[A\n","Downloading (…)l-00007-of-00008.bin:   9% 94.4M/1.07G [00:00<00:02, 441MB/s]\u001b[A\n","Downloading (…)l-00007-of-00008.bin:  14% 147M/1.07G [00:00<00:02, 456MB/s] \u001b[A\n","Downloading (…)l-00007-of-00008.bin:  19% 199M/1.07G [00:00<00:01, 442MB/s]\u001b[A\n","Downloading (…)l-00007-of-00008.bin:  23% 252M/1.07G [00:00<00:01, 422MB/s]\u001b[A\n","Downloading (…)l-00007-of-00008.bin:  28% 304M/1.07G [00:00<00:01, 414MB/s]\u001b[A\n","Downloading (…)l-00007-of-00008.bin:  32% 346M/1.07G [00:00<00:01, 407MB/s]\u001b[A\n","Downloading (…)l-00007-of-00008.bin:  36% 388M/1.07G [00:00<00:01, 399MB/s]\u001b[A\n","Downloading (…)l-00007-of-00008.bin:  40% 430M/1.07G [00:01<00:01, 389MB/s]\u001b[A\n","Downloading (…)l-00007-of-00008.bin:  44% 472M/1.07G [00:01<00:01, 382MB/s]\u001b[A\n","Downloading (…)l-00007-of-00008.bin:  48% 514M/1.07G [00:01<00:01, 375MB/s]\u001b[A\n","Downloading (…)l-00007-of-00008.bin:  52% 556M/1.07G [00:01<00:01, 373MB/s]\u001b[A\n","Downloading (…)l-00007-of-00008.bin:  56% 598M/1.07G [00:01<00:01, 373MB/s]\u001b[A\n","Downloading (…)l-00007-of-00008.bin:  60% 640M/1.07G [00:01<00:01, 381MB/s]\u001b[A\n","Downloading (…)l-00007-of-00008.bin:  64% 692M/1.07G [00:01<00:00, 390MB/s]\u001b[A\n","Downloading (…)l-00007-of-00008.bin:  69% 744M/1.07G [00:01<00:00, 418MB/s]\u001b[A\n","Downloading (…)l-00007-of-00008.bin:  74% 797M/1.07G [00:01<00:00, 441MB/s]\u001b[A\n","Downloading (…)l-00007-of-00008.bin:  79% 849M/1.07G [00:02<00:00, 457MB/s]\u001b[A\n","Downloading (…)l-00007-of-00008.bin:  84% 902M/1.07G [00:02<00:00, 451MB/s]\u001b[A\n","Downloading (…)l-00007-of-00008.bin:  89% 954M/1.07G [00:02<00:00, 435MB/s]\u001b[A\n","Downloading (…)l-00007-of-00008.bin:  94% 1.01G/1.07G [00:02<00:00, 427MB/s]\u001b[A\n","Downloading (…)l-00007-of-00008.bin: 100% 1.07G/1.07G [00:02<00:00, 417MB/s]\n","Downloading shards:  88% 7/8 [00:38<00:05,  5.37s/it]\n","Downloading (…)l-00008-of-00008.bin:   0% 0.00/1.07G [00:00<?, ?B/s]\u001b[A\n","Downloading (…)l-00008-of-00008.bin:   3% 31.5M/1.07G [00:00<00:03, 306MB/s]\u001b[A\n","Downloading (…)l-00008-of-00008.bin:   7% 73.4M/1.07G [00:00<00:03, 319MB/s]\u001b[A\n","Downloading (…)l-00008-of-00008.bin:  12% 126M/1.07G [00:00<00:02, 363MB/s] \u001b[A\n","Downloading (…)l-00008-of-00008.bin:  16% 168M/1.07G [00:00<00:02, 380MB/s]\u001b[A\n","Downloading (…)l-00008-of-00008.bin:  21% 220M/1.07G [00:00<00:02, 401MB/s]\u001b[A\n","Downloading (…)l-00008-of-00008.bin:  25% 273M/1.07G [00:00<00:01, 425MB/s]\u001b[A\n","Downloading (…)l-00008-of-00008.bin:  30% 325M/1.07G [00:00<00:01, 432MB/s]\u001b[A\n","Downloading (…)l-00008-of-00008.bin:  35% 377M/1.07G [00:00<00:01, 413MB/s]\u001b[A\n","Downloading (…)l-00008-of-00008.bin:  39% 419M/1.07G [00:01<00:01, 410MB/s]\u001b[A\n","Downloading (…)l-00008-of-00008.bin:  43% 461M/1.07G [00:01<00:01, 379MB/s]\u001b[A\n","Downloading (…)l-00008-of-00008.bin:  47% 503M/1.07G [00:01<00:01, 373MB/s]\u001b[A\n","Downloading (…)l-00008-of-00008.bin:  52% 556M/1.07G [00:01<00:01, 410MB/s]\u001b[A\n","Downloading (…)l-00008-of-00008.bin:  57% 608M/1.07G [00:01<00:01, 420MB/s]\u001b[A\n","Downloading (…)l-00008-of-00008.bin:  62% 661M/1.07G [00:01<00:00, 436MB/s]\u001b[A\n","Downloading (…)l-00008-of-00008.bin:  67% 713M/1.07G [00:01<00:00, 428MB/s]\u001b[A\n","Downloading (…)l-00008-of-00008.bin:  72% 765M/1.07G [00:01<00:00, 448MB/s]\u001b[A\n","Downloading (…)l-00008-of-00008.bin:  77% 828M/1.07G [00:01<00:00, 480MB/s]\u001b[A\n","Downloading (…)l-00008-of-00008.bin:  83% 891M/1.07G [00:02<00:00, 518MB/s]\u001b[A\n","Downloading (…)l-00008-of-00008.bin:  88% 944M/1.07G [00:02<00:00, 483MB/s]\u001b[A\n","Downloading (…)l-00008-of-00008.bin:  93% 996M/1.07G [00:02<00:00, 477MB/s]\u001b[A\n","Downloading (…)l-00008-of-00008.bin: 100% 1.07G/1.07G [00:02<00:00, 430MB/s]\n","Downloading shards: 100% 8/8 [00:41<00:00,  5.18s/it]\n","[INFO|configuration_utils.py:577] 2023-05-21 11:49:24,652 >> Generate config GenerationConfig {\n","  \"_from_model_config\": true,\n","  \"bos_token_id\": 130004,\n","  \"eos_token_id\": 130005,\n","  \"pad_token_id\": 3,\n","  \"transformers_version\": \"4.29.2\"\n","}\n","\n","Loading checkpoint shards: 100% 8/8 [00:10<00:00,  1.31s/it]\n","[INFO|modeling_utils.py:3185] 2023-05-21 11:49:35,622 >> All model checkpoint weights were used when initializing ChatGLMForConditionalGeneration.\n","\n","[WARNING|modeling_utils.py:3187] 2023-05-21 11:49:35,622 >> Some weights of ChatGLMForConditionalGeneration were not initialized from the model checkpoint at THUDM/chatglm-6b and are newly initialized: ['transformer.prefix_encoder.embedding.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","[INFO|modeling_utils.py:2821] 2023-05-21 11:49:35,894 >> Generation config file not found, using a generation config created from the model config.\n","05/21/2023 11:49:35 - INFO - utils.common - Fine-tuning method: P-Tuning v2\n","trainable params: 29360128 || all params: 6202646528 || trainable%: 0.4733\n","Running tokenizer on dataset:   0% 0/36174 [00:00<?, ? examples/s]05/21/2023 11:49:36 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/suolyer___json/suolyer--webqa-7107602b65a20e87/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-761ae7c32d7f6dea.arrow\n","input_ids:\n","[5, 68600, 75698, 70818, 110780, 130001, 130004, 66113, 63823, 76772, 91155, 20, 70251, 9, 9, 6, 9, 10, 66022, 14, 70805, 69624, 70818, 6, 68765, 63883, 65252, 73763, 75698, 69624, 70818, 6, 63929, 64097, 65252, 73763, 75698, 69624, 70818, 7, 63883, 65252, 65190, 72207, 94928, 6, 79095, 65594, 6, 63829, 64553, 86230, 110717, 89196, 63825, 7, 60, 150, 33, 75982, 63825, 70818, 64446, 63888, 66116, 108447, 65460, 6, 63829, 75811, 82476, 77678, 65810, 65250, 64571, 64782, 72252, 66458, 63825, 75811, 64219, 64223, 63934, 65252, 66081, 63825, 66412, 7, 63827, 76207, 108447, 65460, 6, 75982, 63825, 70818, 6, 73196, 66111, 63825, 92618, 64416, 6, 63915, 80520, 65084, 64416, 63826, 65959, 64416, 6, 63861, 101360, 63826, 68429, 75811, 86476, 118071, 65168, 6, 64268, 63910, 108546, 7, 66111, 63825, 92618, 64416, 74051, 63829, 75811, 72252, 77678, 63825, 71535, 67321, 63826, 109065, 78909, 65270, 6, 80520, 65084, 64416, 63826, 65959, 64416, 75118, 63827, 75811, 72252, 77678, 76697, 63880, 63987, 6, 64019, 64307, 64955, 65662, 68548, 7, 75811, 86476, 65390, 71873, 106083, 65781, 64391, 65754, 63826, 65098, 67451, 64391, 66079, 63825, 70818, 64616, 7, 75982, 63825, 70818, 63827, 63834, 68429, 66999, 64091, 65041, 65298, 65250, 72925, 64086, 64142, 65420, 64026, 63925, 64928, 64917, 6, 63873, 97745, 69855, 72252, 77678, 63825, 65311, 7, 75982, 70818, 67280, 6, 67333, 80484, 75811, 72252, 77678, 65311, 65853, 77420, 6, 64337, 70561, 65270, 6, 65872, 77314, 67369, 65098, 67280, 7, 60, 150, 33, 75982, 63825, 92618, 64416, 63832, 9, 10, 8, 8, 85410, 67280, 7, 63862, 64416, 63832, 95412, 97323, 7, 66852, 64416, 64424, 88507, 92618, 64416, 6, 65959, 64416, 92186, 16, 8, 8, 97323, 7, 65050, 63859, 71752, 63851, 65490, 6, 64712, 64748, 63861, 71011, 64860, 6, 63873, 64004, 85712, 6, 65346, 79095, 117059, 7, 130005]\n","inputs:\n","世界上最早的报纸诞生于 中国。北宋末年(公元11,12世纪)出现的印刷报纸,不仅是中国新闻史上最早的印刷报纸,也是世界新闻史上最早的印刷报纸.中国新闻事业历史的悠久,内容的丰富,是任何西方国家都难以比肩的.<e>中国古代的报纸产生于中国的封建社会时期,是封建地主阶级及其政治代表占统治地位的封建自然经济通过新闻手段的反映.在漫长的封建社会时期,中国古代的报纸,不论是官方的邸报,还是民办的小报和京报,都必然要和当时的封建统治者保持一定的联系,受他们的制约.官方的邸报固然是封建统治阶级的喉舌和御用的宣传工具,民办的小报和京报也只能在封建统治阶级的控制下活动,不能越雷池一步.封建统治者绝不允许可以自由报道一切消息和自由发表一切意见的报纸存在.中国古代的报纸在为当时的读者提供朝野政治和社会信息方面确实起过一定的作用,但始终没有摆脱统治阶级的掌握.中国古代报纸的历史,基本上是一部封建统治阶级掌握传播媒介,控制舆论工具,限制言论出版自由的历史.<e>中国古代的邸报有1200年左右的历史.小报有近千年的历史.民间报房出版的邸报,京报有近400年的历史.它们从诞生到结束,持续的时间都不算短,但发展不快,形式内容的变化不大.\n","label_ids:\n","[-100, -100, -100, -100, -100, -100, 130004, 66113, 63823, 76772, 91155, 20, 70251, 9, 9, 6, 9, 10, 66022, 14, 70805, 69624, 70818, 6, 68765, 63883, 65252, 73763, 75698, 69624, 70818, 6, 63929, 64097, 65252, 73763, 75698, 69624, 70818, 7, 63883, 65252, 65190, 72207, 94928, 6, 79095, 65594, 6, 63829, 64553, 86230, 110717, 89196, 63825, 7, 60, 150, 33, 75982, 63825, 70818, 64446, 63888, 66116, 108447, 65460, 6, 63829, 75811, 82476, 77678, 65810, 65250, 64571, 64782, 72252, 66458, 63825, 75811, 64219, 64223, 63934, 65252, 66081, 63825, 66412, 7, 63827, 76207, 108447, 65460, 6, 75982, 63825, 70818, 6, 73196, 66111, 63825, 92618, 64416, 6, 63915, 80520, 65084, 64416, 63826, 65959, 64416, 6, 63861, 101360, 63826, 68429, 75811, 86476, 118071, 65168, 6, 64268, 63910, 108546, 7, 66111, 63825, 92618, 64416, 74051, 63829, 75811, 72252, 77678, 63825, 71535, 67321, 63826, 109065, 78909, 65270, 6, 80520, 65084, 64416, 63826, 65959, 64416, 75118, 63827, 75811, 72252, 77678, 76697, 63880, 63987, 6, 64019, 64307, 64955, 65662, 68548, 7, 75811, 86476, 65390, 71873, 106083, 65781, 64391, 65754, 63826, 65098, 67451, 64391, 66079, 63825, 70818, 64616, 7, 75982, 63825, 70818, 63827, 63834, 68429, 66999, 64091, 65041, 65298, 65250, 72925, 64086, 64142, 65420, 64026, 63925, 64928, 64917, 6, 63873, 97745, 69855, 72252, 77678, 63825, 65311, 7, 75982, 70818, 67280, 6, 67333, 80484, 75811, 72252, 77678, 65311, 65853, 77420, 6, 64337, 70561, 65270, 6, 65872, 77314, 67369, 65098, 67280, 7, 60, 150, 33, 75982, 63825, 92618, 64416, 63832, 9, 10, 8, 8, 85410, 67280, 7, 63862, 64416, 63832, 95412, 97323, 7, 66852, 64416, 64424, 88507, 92618, 64416, 6, 65959, 64416, 92186, 16, 8, 8, 97323, 7, 65050, 63859, 71752, 63851, 65490, 6, 64712, 64748, 63861, 71011, 64860, 6, 63873, 64004, 85712, 6, 65346, 79095, 117059, 7, 130005]\n","labels:\n","中国。北宋末年(公元11,12世纪)出现的印刷报纸,不仅是中国新闻史上最早的印刷报纸,也是世界新闻史上最早的印刷报纸.中国新闻事业历史的悠久,内容的丰富,是任何西方国家都难以比肩的.<e>中国古代的报纸产生于中国的封建社会时期,是封建地主阶级及其政治代表占统治地位的封建自然经济通过新闻手段的反映.在漫长的封建社会时期,中国古代的报纸,不论是官方的邸报,还是民办的小报和京报,都必然要和当时的封建统治者保持一定的联系,受他们的制约.官方的邸报固然是封建统治阶级的喉舌和御用的宣传工具,民办的小报和京报也只能在封建统治阶级的控制下活动,不能越雷池一步.封建统治者绝不允许可以自由报道一切消息和自由发表一切意见的报纸存在.中国古代的报纸在为当时的读者提供朝野政治和社会信息方面确实起过一定的作用,但始终没有摆脱统治阶级的掌握.中国古代报纸的历史,基本上是一部封建统治阶级掌握传播媒介,控制舆论工具,限制言论出版自由的历史.<e>中国古代的邸报有1200年左右的历史.小报有近千年的历史.民间报房出版的邸报,京报有近400年的历史.它们从诞生到结束,持续的时间都不算短,但发展不快,形式内容的变化不大.\n","[INFO|trainer.py:622] 2023-05-21 11:50:03,263 >> Using cuda_amp half precision backend\n","[INFO|trainer.py:1779] 2023-05-21 11:50:03,271 >> ***** Running training *****\n","[INFO|trainer.py:1780] 2023-05-21 11:50:03,271 >>   Num examples = 36,174\n","[INFO|trainer.py:1781] 2023-05-21 11:50:03,271 >>   Num Epochs = 3\n","[INFO|trainer.py:1782] 2023-05-21 11:50:03,271 >>   Instantaneous batch size per device = 8\n","[INFO|trainer.py:1783] 2023-05-21 11:50:03,271 >>   Total train batch size (w. parallel, distributed & accumulation) = 32\n","[INFO|trainer.py:1784] 2023-05-21 11:50:03,271 >>   Gradient Accumulation steps = 4\n","[INFO|trainer.py:1785] 2023-05-21 11:50:03,271 >>   Total optimization steps = 3,390\n","[INFO|trainer.py:1786] 2023-05-21 11:50:03,272 >>   Number of trainable parameters = 29,360,128\n","{'loss': 3.5614, 'learning_rate': 0.019999652181358435, 'epoch': 0.01}\n","{'loss': 3.2128, 'learning_rate': 0.01999844987637693, 'epoch': 0.02}\n","{'loss': 3.0113, 'learning_rate': 0.019996388894228785, 'epoch': 0.03}\n","{'loss': 2.9555, 'learning_rate': 0.01999346941191327, 'epoch': 0.04}\n","{'loss': 2.9875, 'learning_rate': 0.019989691680158534, 'epoch': 0.04}\n","{'loss': 3.0275, 'learning_rate': 0.01998505602340006, 'epoch': 0.05}\n","{'loss': 2.9219, 'learning_rate': 0.019979562839752833, 'epoch': 0.06}\n","{'loss': 2.9273, 'learning_rate': 0.01997321260097711, 'epoch': 0.07}\n","{'loss': 2.9079, 'learning_rate': 0.019966005852437935, 'epoch': 0.08}\n","{'loss': 2.9218, 'learning_rate': 0.019957943213058296, 'epoch': 0.09}\n","{'loss': 2.8992, 'learning_rate': 0.019949025375265956, 'epoch': 0.1}\n","{'loss': 2.8569, 'learning_rate': 0.019939253104934, 'epoch': 0.11}\n","{'loss': 2.9145, 'learning_rate': 0.01992862724131507, 'epoch': 0.11}\n","{'loss': 2.8506, 'learning_rate': 0.01991714869696927, 'epoch': 0.12}\n","{'loss': 2.8823, 'learning_rate': 0.019904818457685797, 'epoch': 0.13}\n","{'loss': 2.8563, 'learning_rate': 0.0198916375823983, 'epoch': 0.14}\n","{'loss': 2.862, 'learning_rate': 0.019877607203093912, 'epoch': 0.15}\n","{'loss': 2.9152, 'learning_rate': 0.019862728524716045, 'epoch': 0.16}\n","{'loss': 2.8077, 'learning_rate': 0.019847002825060914, 'epoch': 0.17}\n","{'loss': 2.8752, 'learning_rate': 0.019830431454667802, 'epoch': 0.18}\n","{'loss': 2.8652, 'learning_rate': 0.01981301583670304, 'epoch': 0.19}\n","{'loss': 2.8221, 'learning_rate': 0.019794757466837835, 'epoch': 0.19}\n","{'loss': 2.709, 'learning_rate': 0.019775657913119776, 'epoch': 0.2}\n","{'loss': 2.8941, 'learning_rate': 0.019755718815838205, 'epoch': 0.21}\n","{'loss': 2.8091, 'learning_rate': 0.019734941887383308, 'epoch': 0.22}\n","{'loss': 2.8671, 'learning_rate': 0.019713328912099096, 'epoch': 0.23}\n","{'loss': 2.843, 'learning_rate': 0.019690881746130127, 'epoch': 0.24}\n","{'loss': 2.8217, 'learning_rate': 0.019667602317262122, 'epoch': 0.25}\n","{'loss': 2.828, 'learning_rate': 0.01964349262475639, 'epoch': 0.26}\n","{'loss': 2.7985, 'learning_rate': 0.019618554739178142, 'epoch': 0.27}\n","{'loss': 2.7738, 'learning_rate': 0.019592790802218655, 'epoch': 0.27}\n","{'loss': 2.778, 'learning_rate': 0.019566203026511363, 'epoch': 0.28}\n","{'loss': 2.7096, 'learning_rate': 0.0195387936954418, 'epoch': 0.29}\n","{'loss': 2.7533, 'learning_rate': 0.019510565162951538, 'epoch': 0.3}\n","{'loss': 2.7553, 'learning_rate': 0.019481519853335995, 'epoch': 0.31}\n","{'loss': 2.9076, 'learning_rate': 0.01945166026103626, 'epoch': 0.32}\n","{'loss': 2.7707, 'learning_rate': 0.019420988950424857, 'epoch': 0.33}\n","{'loss': 2.8281, 'learning_rate': 0.019389508555585508, 'epoch': 0.34}\n","{'loss': 2.767, 'learning_rate': 0.019357221780086923, 'epoch': 0.34}\n","{'loss': 2.742, 'learning_rate': 0.019324131396750616, 'epoch': 0.35}\n","{'loss': 2.8251, 'learning_rate': 0.019290240247412768, 'epoch': 0.36}\n","{'loss': 2.9557, 'learning_rate': 0.019255551242680163, 'epoch': 0.37}\n","{'loss': 2.7974, 'learning_rate': 0.01922006736168024, 'epoch': 0.38}\n","{'loss': 2.7516, 'learning_rate': 0.019183791651805216, 'epoch': 0.39}\n","{'loss': 2.7441, 'learning_rate': 0.019146727228450396, 'epoch': 0.4}\n","{'loss': 2.8426, 'learning_rate': 0.019108877274746607, 'epoch': 0.41}\n","{'loss': 2.6935, 'learning_rate': 0.01907024504128683, 'epoch': 0.42}\n","{'loss': 2.8522, 'learning_rate': 0.01903083384584704, 'epoch': 0.42}\n","{'loss': 2.6811, 'learning_rate': 0.018990647073101267, 'epoch': 0.43}\n","{'loss': 2.7933, 'learning_rate': 0.018949688174330914, 'epoch': 0.44}\n","{'loss': 2.7864, 'learning_rate': 0.01890796066712837, 'epoch': 0.45}\n","{'loss': 2.8423, 'learning_rate': 0.018865468135094904, 'epoch': 0.46}\n","{'loss': 2.8386, 'learning_rate': 0.018822214227532903, 'epoch': 0.47}\n","{'loss': 2.782, 'learning_rate': 0.018778202659132465, 'epoch': 0.48}\n","{'loss': 2.8733, 'learning_rate': 0.018733437209652388, 'epoch': 0.49}\n","{'loss': 2.831, 'learning_rate': 0.01868792172359555, 'epoch': 0.5}\n","{'loss': 2.7982, 'learning_rate': 0.018641660109878746, 'epoch': 0.5}\n","{'loss': 2.7506, 'learning_rate': 0.018594656341496967, 'epoch': 0.51}\n","{'loss': 2.794, 'learning_rate': 0.01854691445518223, 'epoch': 0.52}\n","{'loss': 2.7669, 'learning_rate': 0.018498438551056876, 'epoch': 0.53}\n","{'loss': 2.758, 'learning_rate': 0.018449232792281434, 'epoch': 0.54}\n","{'loss': 2.7392, 'learning_rate': 0.018399301404697126, 'epoch': 0.55}\n","{'loss': 2.7475, 'learning_rate': 0.018348648676462905, 'epoch': 0.56}\n","{'loss': 2.7266, 'learning_rate': 0.01829727895768721, 'epoch': 0.57}\n","{'loss': 2.8961, 'learning_rate': 0.018245196660054364, 'epoch': 0.57}\n","{'loss': 2.8102, 'learning_rate': 0.018192406256445692, 'epoch': 0.58}\n","{'loss': 2.7038, 'learning_rate': 0.0181389122805554, 'epoch': 0.59}\n","{'loss': 2.766, 'learning_rate': 0.01808471932650119, 'epoch': 0.6}\n","{'loss': 2.7153, 'learning_rate': 0.01802983204842974, 'epoch': 0.61}\n","{'loss': 2.7762, 'learning_rate': 0.017974255160116984, 'epoch': 0.62}\n","{'loss': 2.7999, 'learning_rate': 0.01791799343456329, 'epoch': 0.63}\n","{'loss': 2.7813, 'learning_rate': 0.017861051703583573, 'epoch': 0.64}\n","{'loss': 2.7201, 'learning_rate': 0.017803434857392286, 'epoch': 0.65}\n","{'loss': 2.8102, 'learning_rate': 0.017745147844183486, 'epoch': 0.65}\n","{'loss': 2.799, 'learning_rate': 0.01768619566970586, 'epoch': 0.66}\n","{'loss': 2.7219, 'learning_rate': 0.017626583396832835, 'epoch': 0.67}\n","{'loss': 2.7369, 'learning_rate': 0.017566316145127762, 'epoch': 0.68}\n","{'loss': 2.8864, 'learning_rate': 0.017505399090404244, 'epoch': 0.69}\n","{'loss': 2.7217, 'learning_rate': 0.017443837464281655, 'epoch': 0.7}\n","{'loss': 2.7958, 'learning_rate': 0.0173816365537358, 'epoch': 0.71}\n","{'loss': 2.802, 'learning_rate': 0.017318801700644898, 'epoch': 0.72}\n","{'loss': 2.776, 'learning_rate': 0.017255338301330813, 'epoch': 0.73}\n","{'loss': 2.7919, 'learning_rate': 0.0171912518060956, 'epoch': 0.73}\n","{'loss': 2.8106, 'learning_rate': 0.017126547718753434, 'epoch': 0.74}\n","{'loss': 2.7416, 'learning_rate': 0.017061231596157928, 'epoch': 0.75}\n","{'loss': 2.6574, 'learning_rate': 0.01699530904772492, 'epoch': 0.76}\n","{'loss': 2.7788, 'learning_rate': 0.016928785734950734, 'epoch': 0.77}\n","{'loss': 2.7245, 'learning_rate': 0.01686166737092593, 'epoch': 0.78}\n","{'loss': 2.723, 'learning_rate': 0.016793959719844702, 'epoch': 0.79}\n","{'loss': 2.7483, 'learning_rate': 0.01672566859650981, 'epoch': 0.8}\n","{'loss': 2.7723, 'learning_rate': 0.01665679986583322, 'epoch': 0.8}\n","{'loss': 2.7283, 'learning_rate': 0.016587359442332406, 'epoch': 0.81}\n","{'loss': 2.7196, 'learning_rate': 0.016517353289622415, 'epoch': 0.82}\n","{'loss': 2.7821, 'learning_rate': 0.0164467874199037, 'epoch': 0.83}\n","{'loss': 2.7783, 'learning_rate': 0.01637566789344578, 'epoch': 0.84}\n","{'loss': 2.816, 'learning_rate': 0.016304000818066787, 'epoch': 0.85}\n","{'loss': 2.7713, 'learning_rate': 0.01623179234860893, 'epoch': 0.86}\n","{'loss': 2.9256, 'learning_rate': 0.01615904868640988, 'epoch': 0.87}\n","{'loss': 2.8332, 'learning_rate': 0.016085776078770223, 'epoch': 0.88}\n","{'loss': 2.7069, 'learning_rate': 0.016011980818416923, 'epoch': 0.88}\n"," 29% 1000/3390 [49:16<1:55:07,  2.89s/it]05/21/2023 12:39:19 - INFO - utils.seq2seq - Saving model checkpoint to /content/sft_checkpoint/checkpoint-1000\n","{'loss': 2.709, 'learning_rate': 0.015937669242962898, 'epoch': 0.89}\n","{'loss': 2.7649, 'learning_rate': 0.01586284773436273, 'epoch': 0.9}\n","{'loss': 2.7242, 'learning_rate': 0.015787522718364595, 'epoch': 0.91}\n","{'loss': 2.7979, 'learning_rate': 0.015711700663958397, 'epoch': 0.92}\n","{'loss': 2.6876, 'learning_rate': 0.01563538808282021, 'epoch': 0.93}\n","{'loss': 2.7424, 'learning_rate': 0.015558591528753048, 'epoch': 0.94}\n","{'loss': 2.7339, 'learning_rate': 0.01548131759712402, 'epoch': 0.95}\n","{'loss': 2.7205, 'learning_rate': 0.015403572924297917, 'epoch': 0.96}\n","{'loss': 2.79, 'learning_rate': 0.015325364187067255, 'epoch': 0.96}\n","{'loss': 2.7112, 'learning_rate': 0.015246698102078892, 'epoch': 0.97}\n","{'loss': 2.6312, 'learning_rate': 0.01516758142525717, 'epoch': 0.98}\n","{'loss': 2.8086, 'learning_rate': 0.015088020951223736, 'epoch': 0.99}\n","{'loss': 2.6926, 'learning_rate': 0.015008023512713986, 'epoch': 1.0}\n","{'loss': 2.5627, 'learning_rate': 0.01492759597999028, 'epoch': 1.01}\n","{'loss': 2.655, 'learning_rate': 0.01484674526025191, 'epoch': 1.02}\n","{'loss': 2.5773, 'learning_rate': 0.01476547829704191, 'epoch': 1.03}\n","{'loss': 2.6211, 'learning_rate': 0.014683802069650725, 'epoch': 1.03}\n","{'loss': 2.642, 'learning_rate': 0.014601723592516826, 'epoch': 1.04}\n","{'loss': 2.5517, 'learning_rate': 0.014519249914624322, 'epoch': 1.05}\n","{'loss': 2.6502, 'learning_rate': 0.01443638811889755, 'epoch': 1.06}\n","{'loss': 2.5703, 'learning_rate': 0.01435314532159282, 'epoch': 1.07}\n","{'loss': 2.6949, 'learning_rate': 0.014269528671687244, 'epoch': 1.08}\n","{'loss': 2.6209, 'learning_rate': 0.01418554535026478, 'epoch': 1.09}\n","{'loss': 2.6392, 'learning_rate': 0.014101202569899518, 'epoch': 1.1}\n","{'loss': 2.6025, 'learning_rate': 0.014016507574036247, 'epoch': 1.11}\n","{'loss': 2.5669, 'learning_rate': 0.013931467636368385, 'epoch': 1.11}\n","{'loss': 2.634, 'learning_rate': 0.013846090060213308, 'epoch': 1.12}\n","{'loss': 2.6593, 'learning_rate': 0.01376038217788514, 'epoch': 1.13}\n","{'loss': 2.6919, 'learning_rate': 0.013674351350065029, 'epoch': 1.14}\n","{'loss': 2.6511, 'learning_rate': 0.01358800496516902, 'epoch': 1.15}\n","{'loss': 2.548, 'learning_rate': 0.01350135043871352, 'epoch': 1.16}\n","{'loss': 2.5996, 'learning_rate': 0.01341439521267846, 'epoch': 1.17}\n","{'loss': 2.4723, 'learning_rate': 0.013327146754868147, 'epoch': 1.18}\n","{'loss': 2.7157, 'learning_rate': 0.013239612558269942, 'epoch': 1.19}\n","{'loss': 2.5897, 'learning_rate': 0.013151800140410747, 'epoch': 1.19}\n","{'loss': 2.6022, 'learning_rate': 0.013063717042711396, 'epoch': 1.2}\n","{'loss': 2.5946, 'learning_rate': 0.012975370829838977, 'epoch': 1.21}\n","{'loss': 2.6027, 'learning_rate': 0.012886769089057188, 'epoch': 1.22}\n","{'loss': 2.6053, 'learning_rate': 0.012797919429574721, 'epoch': 1.23}\n","{'loss': 2.5877, 'learning_rate': 0.012708829481891787, 'epoch': 1.24}\n","{'loss': 2.6105, 'learning_rate': 0.012619506897144788, 'epoch': 1.25}\n","{'loss': 2.6186, 'learning_rate': 0.012529959346449245, 'epoch': 1.26}\n","{'loss': 2.6595, 'learning_rate': 0.012440194520240975, 'epoch': 1.26}\n","{'loss': 2.5172, 'learning_rate': 0.012350220127615656, 'epoch': 1.27}\n","{'loss': 2.6651, 'learning_rate': 0.012260043895666728, 'epoch': 1.28}\n","{'loss': 2.6596, 'learning_rate': 0.012169673568821815, 'epoch': 1.29}\n","{'loss': 2.6459, 'learning_rate': 0.012079116908177591, 'epoch': 1.3}\n","{'loss': 2.65, 'learning_rate': 0.011988381690833296, 'epoch': 1.31}\n","{'loss': 2.6436, 'learning_rate': 0.011897475709222779, 'epoch': 1.32}\n","{'loss': 2.6238, 'learning_rate': 0.01180640677044531, 'epoch': 1.33}\n","{'loss': 2.573, 'learning_rate': 0.011715182695595088, 'epoch': 1.34}\n","{'loss': 2.5301, 'learning_rate': 0.011623811319089555, 'epoch': 1.34}\n","{'loss': 2.6205, 'learning_rate': 0.011532300487996574, 'epoch': 1.35}\n","{'loss': 2.5245, 'learning_rate': 0.011440658061360512, 'epoch': 1.36}\n","{'loss': 2.5633, 'learning_rate': 0.01134889190952729, 'epoch': 1.37}\n","{'loss': 2.6587, 'learning_rate': 0.011257009913468483, 'epoch': 1.38}\n","{'loss': 2.5864, 'learning_rate': 0.011165019964104485, 'epoch': 1.39}\n","{'loss': 2.54, 'learning_rate': 0.011072929961626836, 'epoch': 1.4}\n","{'loss': 2.4517, 'learning_rate': 0.010980747814819732, 'epoch': 1.41}\n","{'loss': 2.586, 'learning_rate': 0.010888481440380817, 'epoch': 1.42}\n","{'loss': 2.6102, 'learning_rate': 0.010796138762241307, 'epoch': 1.42}\n","{'loss': 2.5769, 'learning_rate': 0.010703727710885439, 'epoch': 1.43}\n","{'loss': 2.6204, 'learning_rate': 0.010611256222669422, 'epoch': 1.44}\n","{'loss': 2.5469, 'learning_rate': 0.010518732239139848, 'epoch': 1.45}\n","{'loss': 2.5897, 'learning_rate': 0.010426163706351655, 'epoch': 1.46}\n","{'loss': 2.6431, 'learning_rate': 0.010333558574185712, 'epoch': 1.47}\n","{'loss': 2.6256, 'learning_rate': 0.010240924795666094, 'epoch': 1.48}\n","{'loss': 2.4918, 'learning_rate': 0.010148270326277043, 'epoch': 1.49}\n","{'loss': 2.5902, 'learning_rate': 0.01005560312327976, 'epoch': 1.49}\n","{'loss': 2.5903, 'learning_rate': 0.009962931145029018, 'epoch': 1.5}\n","{'loss': 2.4744, 'learning_rate': 0.009870262350289693, 'epoch': 1.51}\n","{'loss': 2.4602, 'learning_rate': 0.00977760469755326, 'epoch': 1.52}\n","{'loss': 2.5271, 'learning_rate': 0.009684966144354318, 'epoch': 1.53}\n","{'loss': 2.6022, 'learning_rate': 0.009592354646587151, 'epoch': 1.54}\n","{'loss': 2.5267, 'learning_rate': 0.009499778157822525, 'epoch': 1.55}\n","{'loss': 2.5625, 'learning_rate': 0.009407244628624568, 'epoch': 1.56}\n","{'loss': 2.6578, 'learning_rate': 0.009314762005868022, 'epoch': 1.57}\n","{'loss': 2.5363, 'learning_rate': 0.009222338232055722, 'epoch': 1.57}\n","{'loss': 2.696, 'learning_rate': 0.009129981244636484, 'epoch': 1.58}\n","{'loss': 2.5861, 'learning_rate': 0.009037698975323454, 'epoch': 1.59}\n","{'loss': 2.6056, 'learning_rate': 0.008945499349412907, 'epoch': 1.6}\n","{'loss': 2.4486, 'learning_rate': 0.008853390285103612, 'epoch': 1.61}\n","{'loss': 2.5652, 'learning_rate': 0.008761379692816826, 'epoch': 1.62}\n","{'loss': 2.5414, 'learning_rate': 0.008669475474516906, 'epoch': 1.63}\n","{'loss': 2.5358, 'learning_rate': 0.008577685523032728, 'epoch': 1.64}\n","{'loss': 2.5293, 'learning_rate': 0.0084860177213798, 'epoch': 1.65}\n","{'loss': 2.6367, 'learning_rate': 0.00839447994208328, 'epoch': 1.65}\n","{'loss': 2.6293, 'learning_rate': 0.008303080046501867, 'epoch': 1.66}\n","{'loss': 2.6215, 'learning_rate': 0.00821182588415268, 'epoch': 1.67}\n","{'loss': 2.6434, 'learning_rate': 0.0081207252920371, 'epoch': 1.68}\n","{'loss': 2.483, 'learning_rate': 0.00802978609396775, 'epoch': 1.69}\n","{'loss': 2.6699, 'learning_rate': 0.007939016099896562, 'epoch': 1.7}\n","{'loss': 2.5618, 'learning_rate': 0.007848423105244053, 'epoch': 1.71}\n","{'loss': 2.5699, 'learning_rate': 0.007758014890229854, 'epoch': 1.72}\n","{'loss': 2.5372, 'learning_rate': 0.007667799219204523, 'epoch': 1.72}\n","{'loss': 2.627, 'learning_rate': 0.007577783839982746, 'epoch': 1.73}\n","{'loss': 2.6423, 'learning_rate': 0.007487976483177944, 'epoch': 1.74}\n","{'loss': 2.7772, 'learning_rate': 0.007398384861538353, 'epoch': 1.75}\n","{'loss': 2.6976, 'learning_rate': 0.007309016669284658, 'epoch': 1.76}\n","{'loss': 2.6002, 'learning_rate': 0.007219879581449194, 'epoch': 1.77}\n"," 59% 2000/3390 [1:38:22<1:17:53,  3.36s/it]05/21/2023 13:28:25 - INFO - utils.seq2seq - Saving model checkpoint to /content/sft_checkpoint/checkpoint-2000\n","{'loss': 2.6425, 'learning_rate': 0.0071309812532168075, 'epoch': 1.78}\n","{'loss': 2.6335, 'learning_rate': 0.00704232931926744, 'epoch': 1.79}\n","{'loss': 2.5108, 'learning_rate': 0.006953931393120414, 'epoch': 1.8}\n","{'loss': 2.5605, 'learning_rate': 0.0068657950664806205, 'epoch': 1.8}\n","{'loss': 2.5517, 'learning_rate': 0.006777927908586512, 'epoch': 1.81}\n","{'loss': 2.6407, 'learning_rate': 0.006690337465560041, 'epoch': 1.82}\n","{'loss': 2.6391, 'learning_rate': 0.006603031259758617, 'epoch': 1.83}\n","{'loss': 2.5994, 'learning_rate': 0.006516016789129052, 'epoch': 1.84}\n","{'loss': 2.6434, 'learning_rate': 0.006429301526563647, 'epoch': 1.85}\n","{'loss': 2.5719, 'learning_rate': 0.006342892919258413, 'epoch': 1.86}\n","{'loss': 2.6509, 'learning_rate': 0.006256798388073473, 'epoch': 1.87}\n","{'loss': 2.5764, 'learning_rate': 0.0061710253268957875, 'epoch': 1.88}\n","{'loss': 2.5622, 'learning_rate': 0.006085581102004138, 'epoch': 1.88}\n","{'loss': 2.573, 'learning_rate': 0.006000473051436499, 'epoch': 1.89}\n","{'loss': 2.6301, 'learning_rate': 0.005915708484359858, 'epoch': 1.9}\n","{'loss': 2.5804, 'learning_rate': 0.005831294680442478, 'epoch': 1.91}\n","{'loss': 2.5961, 'learning_rate': 0.005747238889228727, 'epoch': 1.92}\n","{'loss': 2.548, 'learning_rate': 0.005663548329516477, 'epoch': 1.93}\n","{'loss': 2.6216, 'learning_rate': 0.005580230188737132, 'epoch': 1.94}\n","{'loss': 2.4961, 'learning_rate': 0.0054972916223383775, 'epoch': 1.95}\n","{'loss': 2.5594, 'learning_rate': 0.005414739753169671, 'epoch': 1.95}\n","{'loss': 2.5652, 'learning_rate': 0.0053325816708704975, 'epoch': 1.96}\n","{'loss': 2.5464, 'learning_rate': 0.005250824431261542, 'epoch': 1.97}\n","{'loss': 2.6528, 'learning_rate': 0.005169475055738679, 'epoch': 1.98}\n","{'loss': 2.6255, 'learning_rate': 0.0050885405306700165, 'epoch': 1.99}\n","{'loss': 2.5336, 'learning_rate': 0.005008027806795874, 'epoch': 2.0}\n","{'loss': 2.4085, 'learning_rate': 0.004927943798631848, 'epoch': 2.01}\n","{'loss': 2.413, 'learning_rate': 0.004848295383874982, 'epoch': 2.02}\n","{'loss': 2.4657, 'learning_rate': 0.004769089402813126, 'epoch': 2.03}\n","{'loss': 2.503, 'learning_rate': 0.004690332657737454, 'epoch': 2.03}\n","{'loss': 2.3938, 'learning_rate': 0.004612031912358297, 'epoch': 2.04}\n","{'loss': 2.5097, 'learning_rate': 0.00453419389122426, 'epoch': 2.05}\n","{'loss': 2.5702, 'learning_rate': 0.004456825279144715, 'epoch': 2.06}\n","{'loss': 2.3742, 'learning_rate': 0.004379932720615709, 'epoch': 2.07}\n","{'loss': 2.3427, 'learning_rate': 0.004303522819249307, 'epoch': 2.08}\n","{'loss': 2.419, 'learning_rate': 0.0042276021372064845, 'epoch': 2.09}\n","{'loss': 2.2886, 'learning_rate': 0.004152177194633564, 'epoch': 2.1}\n","{'loss': 2.4128, 'learning_rate': 0.004077254469102246, 'epoch': 2.11}\n","{'loss': 2.3868, 'learning_rate': 0.004002840395053315, 'epoch': 2.11}\n","{'loss': 2.4081, 'learning_rate': 0.00392894136324404, 'epoch': 2.12}\n","{'loss': 2.3705, 'learning_rate': 0.00385556372019934, 'epoch': 2.13}\n","{'loss': 2.3389, 'learning_rate': 0.0037827137676667323, 'epoch': 2.14}\n","{'loss': 2.4766, 'learning_rate': 0.0037103977620751107, 'epoch': 2.15}\n","{'loss': 2.4008, 'learning_rate': 0.0036386219139974752, 'epoch': 2.16}\n","{'loss': 2.4258, 'learning_rate': 0.0035673923876175418, 'epoch': 2.17}\n","{'loss': 2.4068, 'learning_rate': 0.003496715300200346, 'epoch': 2.18}\n","{'loss': 2.4199, 'learning_rate': 0.0034265967215669027, 'epoch': 2.18}\n","{'loss': 2.3979, 'learning_rate': 0.003357042673572914, 'epoch': 2.19}\n","{'loss': 2.4636, 'learning_rate': 0.0032880591295916164, 'epoch': 2.2}\n","{'loss': 2.4394, 'learning_rate': 0.0032196520140007766, 'epoch': 2.21}\n","{'loss': 2.4093, 'learning_rate': 0.003151827201673878, 'epoch': 2.22}\n","{'loss': 2.5328, 'learning_rate': 0.003084590517475623, 'epoch': 2.23}\n","{'loss': 2.4936, 'learning_rate': 0.003017947735761657, 'epoch': 2.24}\n","{'loss': 2.425, 'learning_rate': 0.002951904579882666, 'epoch': 2.25}\n","{'loss': 2.4163, 'learning_rate': 0.002886466721692855, 'epoch': 2.26}\n","{'loss': 2.3496, 'learning_rate': 0.0028216397810628346, 'epoch': 2.26}\n","{'loss': 2.4163, 'learning_rate': 0.0027574293253969993, 'epoch': 2.27}\n","{'loss': 2.3319, 'learning_rate': 0.002693840869155368, 'epoch': 2.28}\n","{'loss': 2.3096, 'learning_rate': 0.0026308798733800133, 'epoch': 2.29}\n","{'loss': 2.4978, 'learning_rate': 0.0025685517452260563, 'epoch': 2.3}\n","{'loss': 2.4018, 'learning_rate': 0.002506861837497302, 'epoch': 2.31}\n","{'loss': 2.3781, 'learning_rate': 0.002445815448186518, 'epoch': 2.32}\n","{'loss': 2.3693, 'learning_rate': 0.0023854178200204534, 'epoch': 2.33}\n","{'loss': 2.4517, 'learning_rate': 0.0023256741400095784, 'epoch': 2.34}\n","{'loss': 2.5043, 'learning_rate': 0.0022665895390026314, 'epoch': 2.34}\n","{'loss': 2.3387, 'learning_rate': 0.0022081690912459585, 'epoch': 2.35}\n","{'loss': 2.3629, 'learning_rate': 0.0021504178139477425, 'epoch': 2.36}\n","{'loss': 2.3, 'learning_rate': 0.002093340666847122, 'epoch': 2.37}\n","{'loss': 2.4988, 'learning_rate': 0.002036942551788242, 'epoch': 2.38}\n","{'loss': 2.4275, 'learning_rate': 0.0019812283122992713, 'epoch': 2.39}\n","{'loss': 2.4665, 'learning_rate': 0.001926202733176442, 'epoch': 2.4}\n","{'loss': 2.3766, 'learning_rate': 0.001871870540073124, 'epoch': 2.41}\n","{'loss': 2.4089, 'learning_rate': 0.0018182363990939887, 'epoch': 2.41}\n","{'loss': 2.396, 'learning_rate': 0.001765304916394267, 'epoch': 2.42}\n","{'loss': 2.4725, 'learning_rate': 0.0017130806377841723, 'epoch': 2.43}\n","{'loss': 2.4086, 'learning_rate': 0.0016615680483385066, 'epoch': 2.44}\n","{'loss': 2.3983, 'learning_rate': 0.0016107715720114779, 'epoch': 2.45}\n","{'loss': 2.4596, 'learning_rate': 0.0015606955712567472, 'epoch': 2.46}\n","{'loss': 2.3927, 'learning_rate': 0.00151134434665281, 'epoch': 2.47}\n","{'loss': 2.4467, 'learning_rate': 0.0014627221365336263, 'epoch': 2.48}\n","{'loss': 2.39, 'learning_rate': 0.0014148331166246532, 'epoch': 2.49}\n","{'loss': 2.3707, 'learning_rate': 0.0013676813996842075, 'epoch': 2.49}\n","{'loss': 2.3253, 'learning_rate': 0.0013212710351502722, 'epoch': 2.5}\n","{'loss': 2.3758, 'learning_rate': 0.0012756060087927236, 'epoch': 2.51}\n","{'loss': 2.2641, 'learning_rate': 0.0012306902423710332, 'epoch': 2.52}\n","{'loss': 2.364, 'learning_rate': 0.0011865275932974428, 'epoch': 2.53}\n","{'loss': 2.4057, 'learning_rate': 0.0011431218543057186, 'epoch': 2.54}\n","{'loss': 2.3533, 'learning_rate': 0.0011004767531253967, 'epoch': 2.55}\n","{'loss': 2.4139, 'learning_rate': 0.0010585959521616651, 'epoch': 2.56}\n","{'loss': 2.3704, 'learning_rate': 0.001017483048180815, 'epoch': 2.57}\n","{'loss': 2.3928, 'learning_rate': 0.0009771415720013566, 'epoch': 2.57}\n","{'loss': 2.4699, 'learning_rate': 0.0009375749881907902, 'epoch': 2.58}\n","{'loss': 2.3868, 'learning_rate': 0.0008987866947680567, 'epoch': 2.59}\n","{'loss': 2.3655, 'learning_rate': 0.0008607800229117169, 'epoch': 2.6}\n","{'loss': 2.4129, 'learning_rate': 0.0008235582366738748, 'epoch': 2.61}\n","{'loss': 2.4135, 'learning_rate': 0.00078712453269984, 'epoch': 2.62}\n","{'loss': 2.4337, 'learning_rate': 0.0007514820399536137, 'epoch': 2.63}\n","{'loss': 2.3682, 'learning_rate': 0.0007166338194491584, 'epoch': 2.64}\n","{'loss': 2.2824, 'learning_rate': 0.0006825828639875165, 'epoch': 2.64}\n","{'loss': 2.32, 'learning_rate': 0.0006493320978997963, 'epoch': 2.65}\n"," 88% 3000/3390 [2:27:30<17:41,  2.72s/it]05/21/2023 14:17:34 - INFO - utils.seq2seq - Saving model checkpoint to /content/sft_checkpoint/checkpoint-3000\n","{'loss': 2.3865, 'learning_rate': 0.0006168843767960108, 'epoch': 2.66}\n","{'loss': 2.3752, 'learning_rate': 0.0005852424873198459, 'epoch': 2.67}\n","{'loss': 2.3801, 'learning_rate': 0.0005544091469093404, 'epoch': 2.68}\n","{'loss': 2.3233, 'learning_rate': 0.0005243870035635023, 'epoch': 2.69}\n","{'loss': 2.4573, 'learning_rate': 0.0004951786356149079, 'epoch': 2.7}\n","{'loss': 2.3035, 'learning_rate': 0.000466786551508257, 'epoch': 2.71}\n","{'loss': 2.4097, 'learning_rate': 0.0004392131895849549, 'epoch': 2.72}\n","{'loss': 2.4462, 'learning_rate': 0.0004124609178737082, 'epoch': 2.72}\n","{'loss': 2.3629, 'learning_rate': 0.0003865320338871459, 'epoch': 2.73}\n","{'loss': 2.3579, 'learning_rate': 0.00036142876442451176, 'epoch': 2.74}\n","{'loss': 2.4441, 'learning_rate': 0.00033715326538042654, 'epoch': 2.75}\n","{'loss': 2.4803, 'learning_rate': 0.00031370762155973455, 'epoch': 2.76}\n","{'loss': 2.433, 'learning_rate': 0.00029109384649845805, 'epoch': 2.77}\n","{'loss': 2.4286, 'learning_rate': 0.0002693138822908781, 'epoch': 2.78}\n","{'loss': 2.5446, 'learning_rate': 0.0002483695994227364, 'epoch': 2.79}\n","{'loss': 2.4441, 'learning_rate': 0.00022826279661060435, 'epoch': 2.8}\n","{'loss': 2.3932, 'learning_rate': 0.00020899520064740162, 'epoch': 2.8}\n","{'loss': 2.2305, 'learning_rate': 0.00019056846625410296, 'epoch': 2.81}\n","{'loss': 2.46, 'learning_rate': 0.00017298417593762495, 'epoch': 2.82}\n","{'loss': 2.3903, 'learning_rate': 0.00015624383985491709, 'epoch': 2.83}\n","{'loss': 2.3836, 'learning_rate': 0.00014034889568327326, 'epoch': 2.84}\n","{'loss': 2.4549, 'learning_rate': 0.00012530070849686158, 'epoch': 2.85}\n","{'loss': 2.5077, 'learning_rate': 0.00011110057064948387, 'epoch': 2.86}\n","{'loss': 2.394, 'learning_rate': 9.774970166359531e-05, 'epoch': 2.87}\n","{'loss': 2.3323, 'learning_rate': 8.524924812556733e-05, 'epoch': 2.87}\n","{'loss': 2.4425, 'learning_rate': 7.360028358721404e-05, 'epoch': 2.88}\n","{'loss': 2.3075, 'learning_rate': 6.280380847360267e-05, 'epoch': 2.89}\n","{'loss': 2.363, 'learning_rate': 5.286074999712675e-05, 'epoch': 2.9}\n","{'loss': 2.4627, 'learning_rate': 4.377196207788203e-05, 'epoch': 2.91}\n","{'loss': 2.505, 'learning_rate': 3.55382252703329e-05, 'epoch': 2.92}\n","{'loss': 2.492, 'learning_rate': 2.8160246696268267e-05, 'epoch': 2.93}\n","{'loss': 2.4373, 'learning_rate': 2.163865998408343e-05, 'epoch': 2.94}\n","{'loss': 2.3919, 'learning_rate': 1.597402521435809e-05, 'epoch': 2.95}\n","{'loss': 2.4211, 'learning_rate': 1.1166828871754798e-05, 'epoch': 2.95}\n","{'loss': 2.4437, 'learning_rate': 7.217483803246827e-06, 'epoch': 2.96}\n","{'loss': 2.4484, 'learning_rate': 4.12632918265099e-06, 'epoch': 2.97}\n","{'loss': 2.4054, 'learning_rate': 1.8936304815087014e-06, 'epoch': 2.98}\n","{'loss': 2.4412, 'learning_rate': 5.195794462820036e-07, 'epoch': 2.99}\n","{'loss': 2.4581, 'learning_rate': 4.294081888955858e-09, 'epoch': 3.0}\n","100% 3390/3390 [2:47:10<00:00,  2.82s/it][INFO|trainer.py:2052] 2023-05-21 14:37:13,655 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 10030.3834, 'train_samples_per_second': 10.819, 'train_steps_per_second': 0.338, 'train_loss': 2.6041226468606684, 'epoch': 3.0}\n","100% 3390/3390 [2:47:10<00:00,  2.96s/it]\n","***** train metrics *****\n","  epoch                    =        3.0\n","  train_loss               =     2.6041\n","  train_runtime            = 2:47:10.38\n","  train_samples_per_second =     10.819\n","  train_steps_per_second   =      0.338\n","05/21/2023 14:37:13 - INFO - utils.seq2seq - Saving model checkpoint to /content/sft_checkpoint\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0 \n","!cd DocQA/finetune/src/ && python train_sft.py \\\n","    --do_train \\\n","    --dataset webqa \\\n","    --finetuning_type p_tuning \\\n","    --output_dir /content/sft_checkpoint \\\n","    --per_device_train_batch_size 8 \\\n","    --gradient_accumulation_steps 4 \\\n","    --lr_scheduler_type cosine \\\n","    --logging_steps 10 \\\n","    --save_steps 1000 \\\n","    --learning_rate 2e-2 \\\n","    --num_train_epochs 3.0 \\\n","    --pre_seq_len 128 \\\n","    --prefix_projection False \\\n","    --fp16"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"5mHfpTlEwWis","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684679892169,"user_tz":-480,"elapsed":56665,"user":{"displayName":"毕弘喆","userId":"15972295281758093677"}},"outputId":"4da1d629-2153-4f18-bd02-0a63b9fb04b7"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-05-21 14:37:19.815925: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","05/21/2023 14:37:22 - INFO - utils.common - Load fine-tuned model from checkpoint(s): /content/sft_checkpoint\n","A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm-6b:\n","- tokenization_chatglm.py\n",". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","Loading checkpoint shards: 100% 8/8 [00:10<00:00,  1.36s/it]\n","Some weights of ChatGLMForConditionalGeneration were not initialized from the model checkpoint at THUDM/chatglm-6b and are newly initialized: ['transformer.prefix_encoder.embedding.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","05/21/2023 14:37:34 - INFO - utils.common - Fine-tuning method: P-Tuning v2\n","trainable params: 0 || all params: 6202646528 || trainable%: 0.0000\n","model and tokenizer have been saved at: /content/output\n"]}],"source":["!cd DocQA/finetune/src/ && python export_model.py \\\n","    --checkpoint_dir /content/sft_checkpoint \\\n","    --output_dir /content/output"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"b_F4c2xeNTvx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684680036754,"user_tz":-480,"elapsed":144587,"user":{"displayName":"毕弘喆","userId":"15972295281758093677"}},"outputId":"b148e15b-a633-4005-c0d7-8d1e5b676c7e"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-05-21 14:38:16.190267: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","05/21/2023 14:38:18 - WARNING - utils.common - Process rank: 0, device: cuda:0, n_gpu: 1\n","  distributed training: True, 16-bits training: False\n","05/21/2023 14:38:18 - INFO - utils.common - Training/evaluation parameters Seq2SeqTrainingArguments(\n","_n_gpu=1,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_backend=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","do_eval=True,\n","do_predict=False,\n","do_train=False,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_steps=None,\n","evaluation_strategy=no,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","generation_config=None,\n","generation_max_length=None,\n","generation_num_beams=None,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_model_id=None,\n","hub_private_repo=False,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_inputs_for_metrics=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=/content/output/runs/May21_14-38-18_5e7a278942ad,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=steps,\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=adamw_torch,\n","optim_args=None,\n","output_dir=/content/output,\n","overwrite_output_dir=False,\n","past_index=-1,\n","per_device_eval_batch_size=2,\n","per_device_train_batch_size=8,\n","predict_with_generate=True,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard'],\n","resume_from_checkpoint=None,\n","run_name=/content/output,\n","save_on_each_node=False,\n","save_safetensors=False,\n","save_steps=500,\n","save_strategy=steps,\n","save_total_limit=None,\n","seed=42,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","sortish_sampler=False,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torchdynamo=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n","xpu_backend=None,\n",")\n","05/21/2023 14:38:18 - INFO - utils.common - Loading dataset DatasetAttr(load_from='hf_hub', dataset_name='suolyer/webqa', file_name=None, file_sha1=None)...\n","05/21/2023 14:38:20 - INFO - datasets.builder - Using custom data configuration suolyer--webqa-7107602b65a20e87\n","05/21/2023 14:38:20 - INFO - datasets.info - Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/json\n","05/21/2023 14:38:20 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n","05/21/2023 14:38:20 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/suolyer___json/suolyer--webqa-7107602b65a20e87/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4\n","05/21/2023 14:38:20 - WARNING - datasets.builder - Found cached dataset json (/root/.cache/huggingface/datasets/suolyer___json/suolyer--webqa-7107602b65a20e87/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n","05/21/2023 14:38:20 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/suolyer___json/suolyer--webqa-7107602b65a20e87/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4\n","100% 3/3 [00:00<00:00, 706.31it/s]\n","05/21/2023 14:38:20 - INFO - utils.common - Load fine-tuned model from checkpoint(s): /content/sft_checkpoint\n","[WARNING|dynamic_module_utils.py:323] 2023-05-21 14:38:20,410 >> A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm-6b:\n","- tokenization_chatglm.py\n",". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","[INFO|tokenization_utils_base.py:1810] 2023-05-21 14:38:20,412 >> loading file ice_text.model from cache at /root/.cache/huggingface/hub/models--THUDM--chatglm-6b/snapshots/a8ede826cf1b62bd3c78bdfb3625c7c5d2048fbd/ice_text.model\n","[INFO|tokenization_utils_base.py:1810] 2023-05-21 14:38:20,412 >> loading file added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:1810] 2023-05-21 14:38:20,412 >> loading file special_tokens_map.json from cache at None\n","[INFO|tokenization_utils_base.py:1810] 2023-05-21 14:38:20,412 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--THUDM--chatglm-6b/snapshots/a8ede826cf1b62bd3c78bdfb3625c7c5d2048fbd/tokenizer_config.json\n","[INFO|configuration_utils.py:669] 2023-05-21 14:38:20,659 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--THUDM--chatglm-6b/snapshots/a8ede826cf1b62bd3c78bdfb3625c7c5d2048fbd/config.json\n","[INFO|configuration_utils.py:669] 2023-05-21 14:38:20,886 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--THUDM--chatglm-6b/snapshots/a8ede826cf1b62bd3c78bdfb3625c7c5d2048fbd/config.json\n","[INFO|configuration_utils.py:725] 2023-05-21 14:38:20,887 >> Model config ChatGLMConfig {\n","  \"_name_or_path\": \"THUDM/chatglm-6b\",\n","  \"architectures\": [\n","    \"ChatGLMModel\"\n","  ],\n","  \"auto_map\": {\n","    \"AutoConfig\": \"THUDM/chatglm-6b--configuration_chatglm.ChatGLMConfig\",\n","    \"AutoModel\": \"THUDM/chatglm-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n","    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm-6b--modeling_chatglm.ChatGLMForConditionalGeneration\"\n","  },\n","  \"bos_token_id\": 130004,\n","  \"eos_token_id\": 130005,\n","  \"gmask_token_id\": 130001,\n","  \"hidden_size\": 4096,\n","  \"inner_hidden_size\": 16384,\n","  \"layernorm_epsilon\": 1e-05,\n","  \"mask_token_id\": 130000,\n","  \"max_sequence_length\": 2048,\n","  \"model_type\": \"chatglm\",\n","  \"num_attention_heads\": 32,\n","  \"num_layers\": 28,\n","  \"pad_token_id\": 3,\n","  \"position_encoding_2d\": true,\n","  \"pre_seq_len\": null,\n","  \"prefix_projection\": false,\n","  \"quantization_bit\": 0,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.29.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 130528\n","}\n","\n","[INFO|modeling_utils.py:2516] 2023-05-21 14:38:21,133 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--THUDM--chatglm-6b/snapshots/a8ede826cf1b62bd3c78bdfb3625c7c5d2048fbd/pytorch_model.bin.index.json\n","[INFO|configuration_utils.py:577] 2023-05-21 14:38:21,135 >> Generate config GenerationConfig {\n","  \"_from_model_config\": true,\n","  \"bos_token_id\": 130004,\n","  \"eos_token_id\": 130005,\n","  \"pad_token_id\": 3,\n","  \"transformers_version\": \"4.29.2\"\n","}\n","\n","Loading checkpoint shards: 100% 8/8 [00:10<00:00,  1.29s/it]\n","[INFO|modeling_utils.py:3185] 2023-05-21 14:38:31,861 >> All model checkpoint weights were used when initializing ChatGLMForConditionalGeneration.\n","\n","[WARNING|modeling_utils.py:3187] 2023-05-21 14:38:31,861 >> Some weights of ChatGLMForConditionalGeneration were not initialized from the model checkpoint at THUDM/chatglm-6b and are newly initialized: ['transformer.prefix_encoder.embedding.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","[INFO|modeling_utils.py:2821] 2023-05-21 14:38:32,130 >> Generation config file not found, using a generation config created from the model config.\n","05/21/2023 14:38:32 - INFO - utils.common - Fine-tuning method: P-Tuning v2\n","trainable params: 0 || all params: 6202646528 || trainable%: 0.0000\n","Running tokenizer on dataset:   0% 0/50 [00:00<?, ? examples/s]05/21/2023 14:38:32 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/suolyer___json/suolyer--webqa-7107602b65a20e87/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-9c230215e1596f8c.arrow\n","input_ids:\n","[5, 68600, 75698, 70818, 110780, 130001, 130004]\n","inputs:\n","世界上最早的报纸诞生于\n","label_ids:\n","[66113, 63823, 76772, 91155, 20, 70251, 9, 9, 6, 9, 10, 66022, 14, 70805, 69624, 70818, 6, 68765, 63883, 65252, 73763, 75698, 69624, 70818, 6, 63929, 64097, 65252, 73763, 75698, 69624, 70818, 7, 63883, 65252, 65190, 72207, 94928, 6, 79095, 65594, 6, 63829, 64553, 86230, 110717, 89196, 63825, 7, 60, 150, 33, 75982, 63825, 70818, 64446, 63888, 66116, 108447, 65460, 6, 63829, 75811, 82476, 77678, 65810, 65250, 64571, 64782, 72252, 66458, 63825, 75811, 64219, 64223, 63934, 65252, 66081, 63825, 66412, 7, 63827, 76207, 108447, 65460, 6, 75982, 63825, 70818, 6, 73196, 66111, 63825, 92618, 64416, 6, 63915, 80520, 65084, 64416, 63826, 65959, 64416, 6, 63861, 101360, 63826, 68429, 75811, 86476, 118071, 65168, 6, 64268, 63910, 108546, 7, 66111, 63825, 92618, 64416, 74051, 63829, 75811, 72252, 77678, 63825, 71535, 67321, 63826, 109065, 78909, 65270, 6, 80520, 65084, 64416, 63826, 65959, 64416, 75118, 63827, 75811, 72252, 77678, 76697, 63880, 63987, 6, 64019, 64307, 64955, 65662, 68548, 7, 75811, 86476, 65390, 71873, 106083, 65781, 64391, 65754, 63826, 65098, 67451, 64391, 66079, 63825, 70818, 64616, 7, 75982, 63825, 70818, 63827, 63834, 68429, 66999, 64091, 65041, 65298, 65250, 72925, 64086, 64142, 65420, 64026, 63925, 64928, 64917, 6, 63873, 97745, 69855, 72252, 77678, 63825, 65311, 7, 75982, 70818, 67280, 6, 67333, 80484, 75811, 72252, 77678, 65311, 65853, 77420, 6, 64337, 70561, 65270, 6, 65872, 77314, 67369, 65098, 67280, 7, 60, 150, 33, 75982, 63825, 92618, 64416, 63832, 9, 10, 8, 8, 85410, 67280, 7, 63862, 64416, 63832, 95412, 97323, 7, 66852, 64416, 64424, 88507, 92618, 64416, 6, 65959, 64416, 92186, 16, 8, 8, 97323, 7, 65050, 63859, 71752, 63851, 65490, 6, 64712, 64748, 63861, 71011, 64860, 6, 63873, 64004, 85712, 6, 65346, 79095, 117059, 7, 130001, 130004]\n","labels:\n","中国。北宋末年(公元11,12世纪)出现的印刷报纸,不仅是中国新闻史上最早的印刷报纸,也是世界新闻史上最早的印刷报纸.中国新闻事业历史的悠久,内容的丰富,是任何西方国家都难以比肩的.<e>中国古代的报纸产生于中国的封建社会时期,是封建地主阶级及其政治代表占统治地位的封建自然经济通过新闻手段的反映.在漫长的封建社会时期,中国古代的报纸,不论是官方的邸报,还是民办的小报和京报,都必然要和当时的封建统治者保持一定的联系,受他们的制约.官方的邸报固然是封建统治阶级的喉舌和御用的宣传工具,民办的小报和京报也只能在封建统治阶级的控制下活动,不能越雷池一步.封建统治者绝不允许可以自由报道一切消息和自由发表一切意见的报纸存在.中国古代的报纸在为当时的读者提供朝野政治和社会信息方面确实起过一定的作用,但始终没有摆脱统治阶级的掌握.中国古代报纸的历史,基本上是一部封建统治阶级掌握传播媒介,控制舆论工具,限制言论出版自由的历史.<e>中国古代的邸报有1200年左右的历史.小报有近千年的历史.民间报房出版的邸报,京报有近400年的历史.它们从诞生到结束,持续的时间都不算短,但发展不快,形式内容的变化不大.\n","[INFO|trainer.py:3165] 2023-05-21 14:38:37,831 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3167] 2023-05-21 14:38:37,831 >>   Num examples = 50\n","[INFO|trainer.py:3170] 2023-05-21 14:38:37,832 >>   Batch size = 2\n","[INFO|configuration_utils.py:577] 2023-05-21 14:38:37,837 >> Generate config GenerationConfig {\n","  \"_from_model_config\": true,\n","  \"bos_token_id\": 130004,\n","  \"eos_token_id\": 130005,\n","  \"pad_token_id\": 3,\n","  \"transformers_version\": \"4.29.2\"\n","}\n","\n","100% 25/25 [01:52<00:00,  2.07s/it]Building prefix dict from the default dictionary ...\n","05/21/2023 14:40:35 - DEBUG - jieba - Building prefix dict from the default dictionary ...\n","Dumping model to file cache /tmp/jieba.cache\n","05/21/2023 14:40:36 - DEBUG - jieba - Dumping model to file cache /tmp/jieba.cache\n","Loading model cost 0.659 seconds.\n","05/21/2023 14:40:36 - DEBUG - jieba - Loading model cost 0.659 seconds.\n","Prefix dict has been built successfully.\n","05/21/2023 14:40:36 - DEBUG - jieba - Prefix dict has been built successfully.\n","100% 25/25 [01:53<00:00,  4.54s/it]\n","***** eval metrics *****\n","  eval_bleu-4             =    61.6443\n","  eval_rouge-1            =    34.0051\n","  eval_rouge-2            =    12.7056\n","  eval_rouge-l            =    26.9627\n","  eval_runtime            = 0:01:59.01\n","  eval_samples_per_second =       0.42\n","  eval_steps_per_second   =       0.21\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0 \n","!cd DocQA/finetune/src/ && python train_sft.py \\\n","    --do_eval \\\n","    --dataset webqa \\\n","    --checkpoint_dir /content/sft_checkpoint \\\n","    --output_dir /content/output \\\n","    --per_device_eval_batch_size 2 \\\n","    --max_samples 50 \\\n","    --predict_with_generate"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"gpuType":"A100","authorship_tag":"ABX9TyNFczfjharfakAQWn1ulzLR"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}